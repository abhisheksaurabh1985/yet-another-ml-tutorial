{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Native and Third Party Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/Desktop/Projects/tf/venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original data frame: (1000, 21)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/abhishek/Desktop/Projects/tf/yet_another_ML_tutorial/coding_exercise/')\n",
    "raw_data = pd.read_csv(\"./CreditDataset.csv\", header=None)\n",
    "print \"Shape of original data frame:\", raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     object\n",
      "1      int64\n",
      "2     object\n",
      "3     object\n",
      "4      int64\n",
      "5     object\n",
      "6     object\n",
      "7      int64\n",
      "8     object\n",
      "9     object\n",
      "10     int64\n",
      "11    object\n",
      "12     int64\n",
      "13    object\n",
      "14    object\n",
      "15     int64\n",
      "16    object\n",
      "17     int64\n",
      "18    object\n",
      "19    object\n",
      "20     int64\n",
      "dtype: object\n",
      "Shape of object data frame: (1000, 13)\n",
      "Shape of int64 data frame: (1000, 8)\n",
      "Type of int data frame: <class 'pandas.core.frame.DataFrame'>\n",
      "Empty DataFrame\n",
      "Columns: [0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Get data types\n",
    "print raw_data.dtypes\n",
    "obj_df = raw_data.select_dtypes(include=['object']).copy()\n",
    "print \"Shape of object data frame:\", obj_df.shape\n",
    "int_df = raw_data.select_dtypes(include=['int64']).copy()\n",
    "print \"Shape of int64 data frame:\", int_df.shape\n",
    "print \"Type of int data frame:\", type(int_df)\n",
    "\n",
    "# Check for null values in the columns containing categorical variables\n",
    "print obj_df[obj_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Please refer the notebook `Classification using Deep Neural Network`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 54)\n",
      "<type 'numpy.ndarray'>\n",
      "(1000, 8)\n",
      "(1000, 62)\n",
      "float64\n",
      "(1000, 63)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding of the columns containing categorical variables\n",
    "# Label encoder\n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = preprocessing.LabelEncoder()\n",
    "# FIT AND TRANSFORM. use df.apply() to apply le.fit_transform to all columns\n",
    "le_obj_df = obj_df.apply(le.fit_transform)\n",
    "# print raw_data.select_dtypes(include=['object']).head(5)\n",
    "# print le_obj_df.head()\n",
    "\n",
    "# One hot encoding of categorical variables\n",
    "# 1. INSTANTIATE\n",
    "encode_object = preprocessing.OneHotEncoder()\n",
    "# 2. FIT\n",
    "encode_object.fit(le_obj_df)\n",
    "# 3. Transform\n",
    "onehotlabels = encode_object.transform(le_obj_df).toarray()\n",
    "print onehotlabels.shape\n",
    "print type(onehotlabels)\n",
    "\n",
    "# Merge the int64 data frame with the one hot labels\n",
    "np_int_df = int_df.as_matrix()\n",
    "print np_int_df.shape\n",
    "processed_data = np.concatenate([onehotlabels, np_int_df], axis=1)\n",
    "print processed_data.shape\n",
    "\n",
    "# print processed_data[:,-1]\n",
    "print processed_data.dtype\n",
    "\n",
    "# One hot encoding of labels. Append the one hot labels in the preprocessed data after \n",
    "# removing the actual labels. This means that the preprocessed data would now have 63 \n",
    "# columns. \n",
    "raw_labels = np.array(processed_data[:,-1]).astype(int)\n",
    "encoded_labels = np.zeros((processed_data[:,-1].shape[0], 2))\n",
    "encoded_labels[np.arange(processed_data[:,-1].shape[0]), raw_labels-1] = 1\n",
    "\n",
    "\n",
    "processed_data = processed_data[:,0:61]\n",
    "processed_data = np.concatenate([processed_data, encoded_labels], axis=1)\n",
    "print processed_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data[:, 0:61],\n",
    "                                                    processed_data[:, 61:63],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 61) (300, 61)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2) (300, 2)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(dataset, batch_size):\n",
    "    sample = dataset[np.random.choice(dataset.shape[0], batch_size, replace=False),:]\n",
    "    last_col_index = dataset.shape[1]-2\n",
    "    x = sample[:,0:last_col_index]\n",
    "    y = sample[:,last_col_index:last_col_index+2]\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input: 61\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "training_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "false_neg_cost = 5\n",
    "weighted_cost = True\n",
    "\n",
    "# Network Parameters\n",
    "num_input = X_train.shape[1] \n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "print \"Number of input:\", num_input\n",
    "print \"Number of classes:\", num_classes\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, num_input])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model weights\n",
    "W = tf.Variable(tf.random_normal([num_input, num_classes]))\n",
    "b = tf.Variable(tf.random_normal([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "if weighted_cost:\n",
    "    cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(\n",
    "              targets=y, logits=pred, pos_weight=false_neg_cost))\n",
    "else:\n",
    "    # Minimize error using cross entropy\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                logits=pred, labels=y))\n",
    "\n",
    "    # cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred + 1e-5), reduction_indices=1))\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0100 cost= 0.666775908\n",
      "Epoch: 0200 cost= 0.648204463\n",
      "Epoch: 0300 cost= 0.645347340\n",
      "Epoch: 0400 cost= 0.651775888\n",
      "Epoch: 0500 cost= 0.662490189\n",
      "Epoch: 0600 cost= 0.648918748\n",
      "Epoch: 0700 cost= 0.653918760\n",
      "Epoch: 0800 cost= 0.646061599\n",
      "Epoch: 0900 cost= 0.640347336\n",
      "Epoch: 1000 cost= 0.659633049\n",
      "Epoch: 1100 cost= 0.644633046\n",
      "Epoch: 1200 cost= 0.649633058\n",
      "Epoch: 1300 cost= 0.662490181\n",
      "Epoch: 1400 cost= 0.652490207\n",
      "Epoch: 1500 cost= 0.650347326\n",
      "Epoch: 1600 cost= 0.631061605\n",
      "Epoch: 1700 cost= 0.650347326\n",
      "Epoch: 1800 cost= 0.661061619\n",
      "Epoch: 1900 cost= 0.665347346\n",
      "Epoch: 2000 cost= 0.655347339\n",
      "Epoch: 2100 cost= 0.651775888\n",
      "Epoch: 2200 cost= 0.657490160\n",
      "Epoch: 2300 cost= 0.670347333\n",
      "Epoch: 2400 cost= 0.648918756\n",
      "Epoch: 2500 cost= 0.651775897\n",
      "Epoch: 2600 cost= 0.669633048\n",
      "Epoch: 2700 cost= 0.653918718\n",
      "Epoch: 2800 cost= 0.636061592\n",
      "Epoch: 2900 cost= 0.661061602\n",
      "Epoch: 3000 cost= 0.657490185\n",
      "Epoch: 3100 cost= 0.657490194\n",
      "Epoch: 3200 cost= 0.654633062\n",
      "Epoch: 3300 cost= 0.641775898\n",
      "Epoch: 3400 cost= 0.653918743\n",
      "Epoch: 3500 cost= 0.653918735\n",
      "Epoch: 3600 cost= 0.660347317\n",
      "Epoch: 3700 cost= 0.649633033\n",
      "Epoch: 3800 cost= 0.650347344\n",
      "Epoch: 3900 cost= 0.666061631\n",
      "Epoch: 4000 cost= 0.666061597\n",
      "Epoch: 4100 cost= 0.654633045\n",
      "Epoch: 4200 cost= 0.651061577\n",
      "Epoch: 4300 cost= 0.664633044\n",
      "Epoch: 4400 cost= 0.667490184\n",
      "Epoch: 4500 cost= 0.648918748\n",
      "Epoch: 4600 cost= 0.654633028\n",
      "Epoch: 4700 cost= 0.673918750\n",
      "Epoch: 4800 cost= 0.671061652\n",
      "Epoch: 4900 cost= 0.659633049\n",
      "Epoch: 5000 cost= 0.661775921\n",
      "Epoch: 5100 cost= 0.659633049\n",
      "Epoch: 5200 cost= 0.651775905\n",
      "Epoch: 5300 cost= 0.650347326\n",
      "Epoch: 5400 cost= 0.654633037\n",
      "Epoch: 5500 cost= 0.658204479\n",
      "Epoch: 5600 cost= 0.647490186\n",
      "Epoch: 5700 cost= 0.666775925\n",
      "Epoch: 5800 cost= 0.642490191\n",
      "Epoch: 5900 cost= 0.640347336\n",
      "Epoch: 6000 cost= 0.653918769\n",
      "Epoch: 6100 cost= 0.660347325\n",
      "Epoch: 6200 cost= 0.651775905\n",
      "Epoch: 6300 cost= 0.648918756\n",
      "Epoch: 6400 cost= 0.651775897\n",
      "Epoch: 6500 cost= 0.651061603\n",
      "Epoch: 6600 cost= 0.662490198\n",
      "Epoch: 6700 cost= 0.641061604\n",
      "Epoch: 6800 cost= 0.647490178\n",
      "Epoch: 6900 cost= 0.653918760\n",
      "Epoch: 7000 cost= 0.655347339\n",
      "Epoch: 7100 cost= 0.660347325\n",
      "Epoch: 7200 cost= 0.643204442\n",
      "Epoch: 7300 cost= 0.644633029\n",
      "Epoch: 7400 cost= 0.663204457\n",
      "Epoch: 7500 cost= 0.638918740\n",
      "Epoch: 7600 cost= 0.648918748\n",
      "Epoch: 7700 cost= 0.650347301\n",
      "Epoch: 7800 cost= 0.658204479\n",
      "Epoch: 7900 cost= 0.655347330\n",
      "Epoch: 8000 cost= 0.648918756\n",
      "Epoch: 8100 cost= 0.643918744\n",
      "Epoch: 8200 cost= 0.657490177\n",
      "Epoch: 8300 cost= 0.656061624\n",
      "Epoch: 8400 cost= 0.656061615\n",
      "Epoch: 8500 cost= 0.643918770\n",
      "Epoch: 8600 cost= 0.668918771\n",
      "Epoch: 8700 cost= 0.647490186\n",
      "Epoch: 8800 cost= 0.653918760\n",
      "Epoch: 8900 cost= 0.650347318\n",
      "Epoch: 9000 cost= 0.647490169\n",
      "Epoch: 9100 cost= 0.662490181\n",
      "Epoch: 9200 cost= 0.641061604\n",
      "Epoch: 9300 cost= 0.643204451\n",
      "Epoch: 9400 cost= 0.658204479\n",
      "Epoch: 9500 cost= 0.659633049\n",
      "Epoch: 9600 cost= 0.670347324\n",
      "Epoch: 9700 cost= 0.646061599\n",
      "Epoch: 9800 cost= 0.650347344\n",
      "Epoch: 9900 cost= 0.656775892\n",
      "Epoch: 10000 cost= 0.662490181\n",
      "Optimization Finished!\n",
      "Accuracy: 0.696667\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(X_train.shape[0]/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = random_batch(np.concatenate([X_train, y_train], axis=1),\n",
    "                                              batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for test data\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "Accuracy of approximately `70%` was obtained in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
