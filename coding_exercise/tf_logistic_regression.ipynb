{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/Desktop/Projects/tf/venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original data frame: (1000, 21)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/abhishek/Desktop/Projects/tf/yet_another_ML_tutorial/coding_exercise/')\n",
    "raw_data = pd.read_csv(\"./CreditDataset.csv\", header=None)\n",
    "print \"Shape of original data frame:\", raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     object\n",
      "1      int64\n",
      "2     object\n",
      "3     object\n",
      "4      int64\n",
      "5     object\n",
      "6     object\n",
      "7      int64\n",
      "8     object\n",
      "9     object\n",
      "10     int64\n",
      "11    object\n",
      "12     int64\n",
      "13    object\n",
      "14    object\n",
      "15     int64\n",
      "16    object\n",
      "17     int64\n",
      "18    object\n",
      "19    object\n",
      "20     int64\n",
      "dtype: object\n",
      "Shape of object data frame: (1000, 13)\n",
      "Shape of int64 data frame: (1000, 8)\n",
      "Type of int data frame: <class 'pandas.core.frame.DataFrame'>\n",
      "Empty DataFrame\n",
      "Columns: [0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Get data types\n",
    "print raw_data.dtypes\n",
    "obj_df = raw_data.select_dtypes(include=['object']).copy()\n",
    "print \"Shape of object data frame:\", obj_df.shape\n",
    "int_df = raw_data.select_dtypes(include=['int64']).copy()\n",
    "print \"Shape of int64 data frame:\", int_df.shape\n",
    "print \"Type of int data frame:\", type(int_df)\n",
    "\n",
    "# Check for null values in the columns containing categorical variables\n",
    "print obj_df[obj_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 54)\n",
      "<type 'numpy.ndarray'>\n",
      "(1000, 8)\n",
      "(1000, 62)\n",
      "float64\n",
      "(1000, 63)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding of the columns containing categorical variables\n",
    "# Label encoder\n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = preprocessing.LabelEncoder()\n",
    "# FIT AND TRANSFORM. use df.apply() to apply le.fit_transform to all columns\n",
    "le_obj_df = obj_df.apply(le.fit_transform)\n",
    "# print raw_data.select_dtypes(include=['object']).head(5)\n",
    "# print le_obj_df.head()\n",
    "\n",
    "# One hot encoding of categorical variables\n",
    "# 1. INSTANTIATE\n",
    "encode_object = preprocessing.OneHotEncoder()\n",
    "# 2. FIT\n",
    "encode_object.fit(le_obj_df)\n",
    "# 3. Transform\n",
    "onehotlabels = encode_object.transform(le_obj_df).toarray()\n",
    "print onehotlabels.shape\n",
    "print type(onehotlabels)\n",
    "\n",
    "# Merge the int64 data frame with the one hot labels\n",
    "np_int_df = int_df.as_matrix()\n",
    "print np_int_df.shape\n",
    "processed_data = np.concatenate([onehotlabels, np_int_df], axis=1)\n",
    "print processed_data.shape\n",
    "\n",
    "# print processed_data[:,-1]\n",
    "print processed_data.dtype\n",
    "\n",
    "# One hot encoding of labels. Append the one hot labels in the preprocessed data after \n",
    "# removing the actual labels. This means that the preprocessed data would now have 63 \n",
    "# columns. \n",
    "raw_labels = np.array(processed_data[:,-1]).astype(int)\n",
    "encoded_labels = np.zeros((processed_data[:,-1].shape[0], 2))\n",
    "encoded_labels[np.arange(processed_data[:,-1].shape[0]), raw_labels-1] = 1\n",
    "\n",
    "\n",
    "processed_data = processed_data[:,0:61]\n",
    "processed_data = np.concatenate([processed_data, encoded_labels], axis=1)\n",
    "print processed_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data[:, 0:61],\n",
    "                                                    processed_data[:, 61:63],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 61) (300, 61)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2) (300, 2)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(dataset, batch_size):\n",
    "    sample = dataset[np.random.choice(dataset.shape[0], batch_size, replace=False),:]\n",
    "    last_col_index = dataset.shape[1]-2\n",
    "    x = sample[:,0:last_col_index]\n",
    "    y = sample[:,last_col_index:last_col_index+2]\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input: 61\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "training_epochs = 25\n",
    "learning_rate = 0.001\n",
    "num_steps = 500000\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = X_train.shape[1] \n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "print \"Number of input:\", num_input\n",
    "print \"Number of classes:\", num_classes\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([num_input, num_classes]))\n",
    "b = tf.Variable(tf.zeros([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 780731.0625, Training Accuracy= 0.210\n",
      "Step 100, Minibatch Loss= 12819.0850, Training Accuracy= 0.700\n",
      "Step 200, Minibatch Loss= 9483.3389, Training Accuracy= 0.650\n",
      "Step 300, Minibatch Loss= 29499.9434, Training Accuracy= 0.300\n",
      "Step 400, Minibatch Loss= 4385.1675, Training Accuracy= 0.480\n",
      "Step 500, Minibatch Loss= 5533.4785, Training Accuracy= 0.470\n",
      "Step 600, Minibatch Loss= 35744.6406, Training Accuracy= 0.290\n",
      "Step 700, Minibatch Loss= 21940.8945, Training Accuracy= 0.350\n",
      "Step 800, Minibatch Loss= 3054.1096, Training Accuracy= 0.710\n",
      "Step 900, Minibatch Loss= 8765.0000, Training Accuracy= 0.770\n",
      "Step 1000, Minibatch Loss= 11961.2773, Training Accuracy= 0.460\n",
      "Step 1100, Minibatch Loss= 11436.5273, Training Accuracy= 0.710\n",
      "Step 1200, Minibatch Loss= 16345.3037, Training Accuracy= 0.670\n",
      "Step 1300, Minibatch Loss= 7451.9771, Training Accuracy= 0.720\n",
      "Step 1400, Minibatch Loss= 8149.7036, Training Accuracy= 0.680\n",
      "Step 1500, Minibatch Loss= 5334.7031, Training Accuracy= 0.590\n",
      "Step 1600, Minibatch Loss= 3596.9382, Training Accuracy= 0.670\n",
      "Step 1700, Minibatch Loss= 8984.7920, Training Accuracy= 0.520\n",
      "Step 1800, Minibatch Loss= 6155.7402, Training Accuracy= 0.680\n",
      "Step 1900, Minibatch Loss= 10272.1777, Training Accuracy= 0.710\n",
      "Step 2000, Minibatch Loss= 25571.0332, Training Accuracy= 0.650\n",
      "Step 2100, Minibatch Loss= 4177.3188, Training Accuracy= 0.610\n",
      "Step 2200, Minibatch Loss= 17016.5332, Training Accuracy= 0.410\n",
      "Step 2300, Minibatch Loss= 13493.5439, Training Accuracy= 0.520\n",
      "Step 2400, Minibatch Loss= 5956.5488, Training Accuracy= 0.760\n",
      "Step 2500, Minibatch Loss= 969.8293, Training Accuracy= 0.790\n",
      "Step 2600, Minibatch Loss= 10493.9736, Training Accuracy= 0.690\n",
      "Step 2700, Minibatch Loss= 3651.9268, Training Accuracy= 0.580\n",
      "Step 2800, Minibatch Loss= 3715.7644, Training Accuracy= 0.670\n",
      "Step 2900, Minibatch Loss= 9910.2090, Training Accuracy= 0.740\n",
      "Step 3000, Minibatch Loss= 7284.0361, Training Accuracy= 0.680\n",
      "Step 3100, Minibatch Loss= 2345.0779, Training Accuracy= 0.670\n",
      "Step 3200, Minibatch Loss= 4397.7158, Training Accuracy= 0.720\n",
      "Step 3300, Minibatch Loss= 7614.9702, Training Accuracy= 0.660\n",
      "Step 3400, Minibatch Loss= 765.3222, Training Accuracy= 0.810\n",
      "Step 3500, Minibatch Loss= 1918.0731, Training Accuracy= 0.740\n",
      "Step 3600, Minibatch Loss= 9448.5898, Training Accuracy= 0.490\n",
      "Step 3700, Minibatch Loss= 1859.1161, Training Accuracy= 0.770\n",
      "Step 3800, Minibatch Loss= 14970.0449, Training Accuracy= 0.750\n",
      "Step 3900, Minibatch Loss= 3243.3462, Training Accuracy= 0.630\n",
      "Step 4000, Minibatch Loss= 4405.7471, Training Accuracy= 0.530\n",
      "Step 4100, Minibatch Loss= 20337.9844, Training Accuracy= 0.660\n",
      "Step 4200, Minibatch Loss= 1718.8115, Training Accuracy= 0.700\n",
      "Step 4300, Minibatch Loss= 1032.2074, Training Accuracy= 0.790\n",
      "Step 4400, Minibatch Loss= 6885.0830, Training Accuracy= 0.720\n",
      "Step 4500, Minibatch Loss= 9445.2080, Training Accuracy= 0.670\n",
      "Step 4600, Minibatch Loss= 2695.5562, Training Accuracy= 0.750\n",
      "Step 4700, Minibatch Loss= 9219.1318, Training Accuracy= 0.700\n",
      "Step 4800, Minibatch Loss= 11225.3896, Training Accuracy= 0.670\n",
      "Step 4900, Minibatch Loss= 2161.4490, Training Accuracy= 0.650\n",
      "Step 5000, Minibatch Loss= 5581.5762, Training Accuracy= 0.730\n",
      "Step 5100, Minibatch Loss= 1469.9047, Training Accuracy= 0.810\n",
      "Step 5200, Minibatch Loss= 4524.6450, Training Accuracy= 0.600\n",
      "Step 5300, Minibatch Loss= 8980.1211, Training Accuracy= 0.780\n",
      "Step 5400, Minibatch Loss= 5717.2900, Training Accuracy= 0.770\n",
      "Step 5500, Minibatch Loss= 10388.9053, Training Accuracy= 0.540\n",
      "Step 5600, Minibatch Loss= 3758.3162, Training Accuracy= 0.710\n",
      "Step 5700, Minibatch Loss= 6450.9893, Training Accuracy= 0.580\n",
      "Step 5800, Minibatch Loss= 8549.2617, Training Accuracy= 0.680\n",
      "Step 5900, Minibatch Loss= 5877.0889, Training Accuracy= 0.790\n",
      "Step 6000, Minibatch Loss= 2351.0120, Training Accuracy= 0.750\n",
      "Step 6100, Minibatch Loss= 4204.9248, Training Accuracy= 0.580\n",
      "Step 6200, Minibatch Loss= 15838.7578, Training Accuracy= 0.470\n",
      "Step 6300, Minibatch Loss= 1788.8934, Training Accuracy= 0.780\n",
      "Step 6400, Minibatch Loss= 2659.1248, Training Accuracy= 0.730\n",
      "Step 6500, Minibatch Loss= 1173.7170, Training Accuracy= 0.850\n",
      "Step 6600, Minibatch Loss= 1163.5571, Training Accuracy= 0.830\n",
      "Step 6700, Minibatch Loss= 5189.0439, Training Accuracy= 0.680\n",
      "Step 6800, Minibatch Loss= 3269.9880, Training Accuracy= 0.740\n",
      "Step 6900, Minibatch Loss= 5935.7168, Training Accuracy= 0.710\n",
      "Step 7000, Minibatch Loss= 3223.5320, Training Accuracy= 0.680\n",
      "Step 7100, Minibatch Loss= 5214.4448, Training Accuracy= 0.750\n",
      "Step 7200, Minibatch Loss= 5021.4326, Training Accuracy= 0.660\n",
      "Step 7300, Minibatch Loss= 10788.3799, Training Accuracy= 0.710\n",
      "Step 7400, Minibatch Loss= 1794.8135, Training Accuracy= 0.800\n",
      "Step 7500, Minibatch Loss= 8402.4336, Training Accuracy= 0.540\n",
      "Step 7600, Minibatch Loss= 1423.4272, Training Accuracy= 0.820\n",
      "Step 7700, Minibatch Loss= 5308.9302, Training Accuracy= 0.830\n",
      "Step 7800, Minibatch Loss= 2391.0635, Training Accuracy= 0.730\n",
      "Step 7900, Minibatch Loss= 17247.4727, Training Accuracy= 0.410\n",
      "Step 8000, Minibatch Loss= 6254.1519, Training Accuracy= 0.550\n",
      "Step 8100, Minibatch Loss= 15503.6338, Training Accuracy= 0.400\n",
      "Step 8200, Minibatch Loss= 2299.8669, Training Accuracy= 0.750\n",
      "Step 8300, Minibatch Loss= 3342.9319, Training Accuracy= 0.640\n",
      "Step 8400, Minibatch Loss= 2210.3315, Training Accuracy= 0.740\n",
      "Step 8500, Minibatch Loss= 6523.9033, Training Accuracy= 0.760\n",
      "Step 8600, Minibatch Loss= 9294.7285, Training Accuracy= 0.690\n",
      "Step 8700, Minibatch Loss= 1294.4745, Training Accuracy= 0.790\n",
      "Step 8800, Minibatch Loss= 5332.3975, Training Accuracy= 0.520\n",
      "Step 8900, Minibatch Loss= 1339.2460, Training Accuracy= 0.790\n",
      "Step 9000, Minibatch Loss= 15447.2686, Training Accuracy= 0.480\n",
      "Step 9100, Minibatch Loss= 1519.9639, Training Accuracy= 0.790\n",
      "Step 9200, Minibatch Loss= 20131.8242, Training Accuracy= 0.390\n",
      "Step 9300, Minibatch Loss= 1672.0444, Training Accuracy= 0.720\n",
      "Step 9400, Minibatch Loss= 6468.3218, Training Accuracy= 0.630\n",
      "Step 9500, Minibatch Loss= 2958.0950, Training Accuracy= 0.730\n",
      "Step 9600, Minibatch Loss= 2559.2212, Training Accuracy= 0.770\n",
      "Step 9700, Minibatch Loss= 6428.7568, Training Accuracy= 0.720\n",
      "Step 9800, Minibatch Loss= 12829.8047, Training Accuracy= 0.710\n",
      "Step 9900, Minibatch Loss= 10339.5996, Training Accuracy= 0.690\n",
      "Step 10000, Minibatch Loss= 2755.0845, Training Accuracy= 0.760\n",
      "Step 10100, Minibatch Loss= 13547.6846, Training Accuracy= 0.470\n",
      "Step 10200, Minibatch Loss= 2025.4783, Training Accuracy= 0.700\n",
      "Step 10300, Minibatch Loss= 986.4247, Training Accuracy= 0.900\n",
      "Step 10400, Minibatch Loss= 1259.5394, Training Accuracy= 0.810\n",
      "Step 10500, Minibatch Loss= 2296.5176, Training Accuracy= 0.730\n",
      "Step 10600, Minibatch Loss= 8701.5723, Training Accuracy= 0.760\n",
      "Step 10700, Minibatch Loss= 2487.6929, Training Accuracy= 0.690\n",
      "Step 10800, Minibatch Loss= 5303.5508, Training Accuracy= 0.740\n",
      "Step 10900, Minibatch Loss= 1559.8315, Training Accuracy= 0.760\n",
      "Step 11000, Minibatch Loss= 1513.3409, Training Accuracy= 0.760\n",
      "Step 11100, Minibatch Loss= 1614.3129, Training Accuracy= 0.750\n",
      "Step 11200, Minibatch Loss= 5162.7930, Training Accuracy= 0.690\n",
      "Step 11300, Minibatch Loss= 5823.4414, Training Accuracy= 0.740\n",
      "Step 11400, Minibatch Loss= 8810.7188, Training Accuracy= 0.730\n",
      "Step 11500, Minibatch Loss= 5741.2202, Training Accuracy= 0.720\n",
      "Step 11600, Minibatch Loss= 7281.4014, Training Accuracy= 0.690\n",
      "Step 11700, Minibatch Loss= 6073.7988, Training Accuracy= 0.730\n",
      "Step 11800, Minibatch Loss= 3183.5537, Training Accuracy= 0.700\n",
      "Step 11900, Minibatch Loss= 1937.3875, Training Accuracy= 0.760\n",
      "Step 12000, Minibatch Loss= 1326.9475, Training Accuracy= 0.830\n",
      "Step 12100, Minibatch Loss= 9035.7354, Training Accuracy= 0.680\n",
      "Step 12200, Minibatch Loss= 1416.0425, Training Accuracy= 0.760\n",
      "Step 12300, Minibatch Loss= 6382.6323, Training Accuracy= 0.700\n",
      "Step 12400, Minibatch Loss= 687.8541, Training Accuracy= 0.820\n",
      "Step 12500, Minibatch Loss= 6551.7339, Training Accuracy= 0.650\n",
      "Step 12600, Minibatch Loss= 5766.0015, Training Accuracy= 0.640\n",
      "Step 12700, Minibatch Loss= 2474.5540, Training Accuracy= 0.760\n",
      "Step 12800, Minibatch Loss= 4978.2114, Training Accuracy= 0.550\n",
      "Step 12900, Minibatch Loss= 1458.4783, Training Accuracy= 0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13000, Minibatch Loss= 2619.3875, Training Accuracy= 0.710\n",
      "Step 13100, Minibatch Loss= 2483.3774, Training Accuracy= 0.710\n",
      "Step 13200, Minibatch Loss= 4710.4956, Training Accuracy= 0.770\n",
      "Step 13300, Minibatch Loss= 8376.9590, Training Accuracy= 0.540\n",
      "Step 13400, Minibatch Loss= 782.0744, Training Accuracy= 0.900\n",
      "Step 13500, Minibatch Loss= 3133.8503, Training Accuracy= 0.780\n",
      "Step 13600, Minibatch Loss= 3582.4111, Training Accuracy= 0.700\n",
      "Step 13700, Minibatch Loss= 1626.2415, Training Accuracy= 0.770\n",
      "Step 13800, Minibatch Loss= 2309.3552, Training Accuracy= 0.800\n",
      "Step 13900, Minibatch Loss= 1377.4655, Training Accuracy= 0.770\n",
      "Step 14000, Minibatch Loss= 46863.2812, Training Accuracy= 0.320\n",
      "Step 14100, Minibatch Loss= 1754.2423, Training Accuracy= 0.710\n",
      "Step 14200, Minibatch Loss= 4439.7363, Training Accuracy= 0.650\n",
      "Step 14300, Minibatch Loss= 4306.2949, Training Accuracy= 0.720\n",
      "Step 14400, Minibatch Loss= 7048.6660, Training Accuracy= 0.580\n",
      "Step 14500, Minibatch Loss= 4788.7246, Training Accuracy= 0.640\n",
      "Step 14600, Minibatch Loss= 5497.1094, Training Accuracy= 0.610\n",
      "Step 14700, Minibatch Loss= 3519.6406, Training Accuracy= 0.740\n",
      "Step 14800, Minibatch Loss= 4179.3140, Training Accuracy= 0.630\n",
      "Step 14900, Minibatch Loss= 4575.8130, Training Accuracy= 0.640\n",
      "Step 15000, Minibatch Loss= 2195.0278, Training Accuracy= 0.750\n",
      "Step 15100, Minibatch Loss= 6658.4067, Training Accuracy= 0.810\n",
      "Step 15200, Minibatch Loss= 10381.1631, Training Accuracy= 0.520\n",
      "Step 15300, Minibatch Loss= 3308.2666, Training Accuracy= 0.690\n",
      "Step 15400, Minibatch Loss= 4976.1133, Training Accuracy= 0.750\n",
      "Step 15500, Minibatch Loss= 1451.4602, Training Accuracy= 0.790\n",
      "Step 15600, Minibatch Loss= 1580.8519, Training Accuracy= 0.780\n",
      "Step 15700, Minibatch Loss= 5226.2241, Training Accuracy= 0.710\n",
      "Step 15800, Minibatch Loss= 2523.0435, Training Accuracy= 0.750\n",
      "Step 15900, Minibatch Loss= 2467.2063, Training Accuracy= 0.790\n",
      "Step 16000, Minibatch Loss= 859.7906, Training Accuracy= 0.800\n",
      "Step 16100, Minibatch Loss= 3124.6968, Training Accuracy= 0.690\n",
      "Step 16200, Minibatch Loss= 1620.1212, Training Accuracy= 0.810\n",
      "Step 16300, Minibatch Loss= 5103.7358, Training Accuracy= 0.770\n",
      "Step 16400, Minibatch Loss= 1805.0686, Training Accuracy= 0.710\n",
      "Step 16500, Minibatch Loss= 4754.2168, Training Accuracy= 0.740\n",
      "Step 16600, Minibatch Loss= 11637.5654, Training Accuracy= 0.740\n",
      "Step 16700, Minibatch Loss= 3494.0835, Training Accuracy= 0.720\n",
      "Step 16800, Minibatch Loss= 2460.9734, Training Accuracy= 0.710\n",
      "Step 16900, Minibatch Loss= 4283.3999, Training Accuracy= 0.730\n",
      "Step 17000, Minibatch Loss= 4080.3535, Training Accuracy= 0.620\n",
      "Step 17100, Minibatch Loss= 1306.5217, Training Accuracy= 0.810\n",
      "Step 17200, Minibatch Loss= 2979.6248, Training Accuracy= 0.640\n",
      "Step 17300, Minibatch Loss= 2032.9867, Training Accuracy= 0.770\n",
      "Step 17400, Minibatch Loss= 1393.2184, Training Accuracy= 0.760\n",
      "Step 17500, Minibatch Loss= 1842.3219, Training Accuracy= 0.780\n",
      "Step 17600, Minibatch Loss= 5706.4746, Training Accuracy= 0.590\n",
      "Step 17700, Minibatch Loss= 12916.8154, Training Accuracy= 0.460\n",
      "Step 17800, Minibatch Loss= 1666.1422, Training Accuracy= 0.780\n",
      "Step 17900, Minibatch Loss= 4873.9814, Training Accuracy= 0.770\n",
      "Step 18000, Minibatch Loss= 8093.9048, Training Accuracy= 0.540\n",
      "Step 18100, Minibatch Loss= 1139.0018, Training Accuracy= 0.790\n",
      "Step 18200, Minibatch Loss= 1999.0112, Training Accuracy= 0.770\n",
      "Step 18300, Minibatch Loss= 8108.1235, Training Accuracy= 0.560\n",
      "Step 18400, Minibatch Loss= 4134.0796, Training Accuracy= 0.700\n",
      "Step 18500, Minibatch Loss= 10061.3164, Training Accuracy= 0.710\n",
      "Step 18600, Minibatch Loss= 3563.3787, Training Accuracy= 0.690\n",
      "Step 18700, Minibatch Loss= 24837.6602, Training Accuracy= 0.680\n",
      "Step 18800, Minibatch Loss= 5540.0864, Training Accuracy= 0.790\n",
      "Step 18900, Minibatch Loss= 5349.1025, Training Accuracy= 0.770\n",
      "Step 19000, Minibatch Loss= 8401.6553, Training Accuracy= 0.590\n",
      "Step 19100, Minibatch Loss= 4787.1846, Training Accuracy= 0.770\n",
      "Step 19200, Minibatch Loss= 4209.4702, Training Accuracy= 0.750\n",
      "Step 19300, Minibatch Loss= 2068.8503, Training Accuracy= 0.750\n",
      "Step 19400, Minibatch Loss= 2864.6318, Training Accuracy= 0.720\n",
      "Step 19500, Minibatch Loss= 12392.7227, Training Accuracy= 0.470\n",
      "Step 19600, Minibatch Loss= 1349.4437, Training Accuracy= 0.780\n",
      "Step 19700, Minibatch Loss= 14593.5225, Training Accuracy= 0.490\n",
      "Step 19800, Minibatch Loss= 6118.0112, Training Accuracy= 0.590\n",
      "Step 19900, Minibatch Loss= 4685.8452, Training Accuracy= 0.610\n",
      "Step 20000, Minibatch Loss= 2011.5447, Training Accuracy= 0.750\n",
      "Step 20100, Minibatch Loss= 1408.0278, Training Accuracy= 0.770\n",
      "Step 20200, Minibatch Loss= 4278.4966, Training Accuracy= 0.710\n",
      "Step 20300, Minibatch Loss= 1978.9929, Training Accuracy= 0.660\n",
      "Step 20400, Minibatch Loss= 7088.1450, Training Accuracy= 0.520\n",
      "Step 20500, Minibatch Loss= 3977.3818, Training Accuracy= 0.630\n",
      "Step 20600, Minibatch Loss= 2346.2656, Training Accuracy= 0.740\n",
      "Step 20700, Minibatch Loss= 2762.7312, Training Accuracy= 0.750\n",
      "Step 20800, Minibatch Loss= 5323.8101, Training Accuracy= 0.730\n",
      "Step 20900, Minibatch Loss= 2653.2068, Training Accuracy= 0.720\n",
      "Step 21000, Minibatch Loss= 2160.1626, Training Accuracy= 0.800\n",
      "Step 21100, Minibatch Loss= 4063.3840, Training Accuracy= 0.780\n",
      "Step 21200, Minibatch Loss= 9750.5410, Training Accuracy= 0.490\n",
      "Step 21300, Minibatch Loss= 2250.6001, Training Accuracy= 0.720\n",
      "Step 21400, Minibatch Loss= 12204.5713, Training Accuracy= 0.720\n",
      "Step 21500, Minibatch Loss= 9050.3984, Training Accuracy= 0.510\n",
      "Step 21600, Minibatch Loss= 3086.9395, Training Accuracy= 0.680\n",
      "Step 21700, Minibatch Loss= 1501.8035, Training Accuracy= 0.790\n",
      "Step 21800, Minibatch Loss= 2269.8149, Training Accuracy= 0.760\n",
      "Step 21900, Minibatch Loss= 7432.9062, Training Accuracy= 0.710\n",
      "Step 22000, Minibatch Loss= 2846.0420, Training Accuracy= 0.770\n",
      "Step 22100, Minibatch Loss= 6076.8066, Training Accuracy= 0.780\n",
      "Step 22200, Minibatch Loss= 7538.0957, Training Accuracy= 0.760\n",
      "Step 22300, Minibatch Loss= 6982.2676, Training Accuracy= 0.780\n",
      "Step 22400, Minibatch Loss= 1610.5359, Training Accuracy= 0.730\n",
      "Step 22500, Minibatch Loss= 18763.6484, Training Accuracy= 0.680\n",
      "Step 22600, Minibatch Loss= 11036.0059, Training Accuracy= 0.450\n",
      "Step 22700, Minibatch Loss= 1217.8293, Training Accuracy= 0.790\n",
      "Step 22800, Minibatch Loss= 2327.2681, Training Accuracy= 0.780\n",
      "Step 22900, Minibatch Loss= 897.5084, Training Accuracy= 0.800\n",
      "Step 23000, Minibatch Loss= 8102.9355, Training Accuracy= 0.760\n",
      "Step 23100, Minibatch Loss= 6581.1777, Training Accuracy= 0.610\n",
      "Step 23200, Minibatch Loss= 7670.4077, Training Accuracy= 0.700\n",
      "Step 23300, Minibatch Loss= 995.0444, Training Accuracy= 0.820\n",
      "Step 23400, Minibatch Loss= 5847.0327, Training Accuracy= 0.650\n",
      "Step 23500, Minibatch Loss= 15438.8926, Training Accuracy= 0.730\n",
      "Step 23600, Minibatch Loss= 6832.9175, Training Accuracy= 0.640\n",
      "Step 23700, Minibatch Loss= 6328.0825, Training Accuracy= 0.710\n",
      "Step 23800, Minibatch Loss= 2544.0510, Training Accuracy= 0.720\n",
      "Step 23900, Minibatch Loss= 1193.0042, Training Accuracy= 0.800\n",
      "Step 24000, Minibatch Loss= 2686.9346, Training Accuracy= 0.810\n",
      "Step 24100, Minibatch Loss= 2257.7307, Training Accuracy= 0.700\n",
      "Step 24200, Minibatch Loss= 5848.7500, Training Accuracy= 0.590\n",
      "Step 24300, Minibatch Loss= 1472.2217, Training Accuracy= 0.750\n",
      "Step 24400, Minibatch Loss= 3123.8538, Training Accuracy= 0.690\n",
      "Step 24500, Minibatch Loss= 4007.5205, Training Accuracy= 0.740\n",
      "Step 24600, Minibatch Loss= 3025.0986, Training Accuracy= 0.720\n",
      "Step 24700, Minibatch Loss= 1348.8257, Training Accuracy= 0.770\n",
      "Step 24800, Minibatch Loss= 6132.1274, Training Accuracy= 0.690\n",
      "Step 24900, Minibatch Loss= 1681.7582, Training Accuracy= 0.740\n",
      "Step 25000, Minibatch Loss= 6876.9336, Training Accuracy= 0.560\n",
      "Step 25100, Minibatch Loss= 6752.6475, Training Accuracy= 0.760\n",
      "Step 25200, Minibatch Loss= 10120.3164, Training Accuracy= 0.550\n",
      "Step 25300, Minibatch Loss= 9721.0723, Training Accuracy= 0.500\n",
      "Step 25400, Minibatch Loss= 3546.0012, Training Accuracy= 0.630\n",
      "Step 25500, Minibatch Loss= 1560.5259, Training Accuracy= 0.810\n",
      "Step 25600, Minibatch Loss= 6151.6606, Training Accuracy= 0.730\n",
      "Step 25700, Minibatch Loss= 7368.2632, Training Accuracy= 0.560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25800, Minibatch Loss= 1755.3243, Training Accuracy= 0.720\n",
      "Step 25900, Minibatch Loss= 1564.6893, Training Accuracy= 0.720\n",
      "Step 26000, Minibatch Loss= 2916.7175, Training Accuracy= 0.690\n",
      "Step 26100, Minibatch Loss= 4729.8745, Training Accuracy= 0.760\n",
      "Step 26200, Minibatch Loss= 863.5269, Training Accuracy= 0.840\n",
      "Step 26300, Minibatch Loss= 1383.2690, Training Accuracy= 0.810\n",
      "Step 26400, Minibatch Loss= 6285.6689, Training Accuracy= 0.700\n",
      "Step 26500, Minibatch Loss= 4307.7651, Training Accuracy= 0.670\n",
      "Step 26600, Minibatch Loss= 4202.7676, Training Accuracy= 0.670\n",
      "Step 26700, Minibatch Loss= 2027.2784, Training Accuracy= 0.700\n",
      "Step 26800, Minibatch Loss= 1388.1200, Training Accuracy= 0.790\n",
      "Step 26900, Minibatch Loss= 8741.0010, Training Accuracy= 0.530\n",
      "Step 27000, Minibatch Loss= 3790.5457, Training Accuracy= 0.620\n",
      "Step 27100, Minibatch Loss= 7353.0845, Training Accuracy= 0.560\n",
      "Step 27200, Minibatch Loss= 1695.6428, Training Accuracy= 0.770\n",
      "Step 27300, Minibatch Loss= 5342.2983, Training Accuracy= 0.570\n",
      "Step 27400, Minibatch Loss= 1875.8031, Training Accuracy= 0.710\n",
      "Step 27500, Minibatch Loss= 3683.8274, Training Accuracy= 0.760\n",
      "Step 27600, Minibatch Loss= 1640.6434, Training Accuracy= 0.750\n",
      "Step 27700, Minibatch Loss= 12316.4727, Training Accuracy= 0.410\n",
      "Step 27800, Minibatch Loss= 1210.0743, Training Accuracy= 0.770\n",
      "Step 27900, Minibatch Loss= 4420.2588, Training Accuracy= 0.780\n",
      "Step 28000, Minibatch Loss= 7916.9746, Training Accuracy= 0.530\n",
      "Step 28100, Minibatch Loss= 2354.9609, Training Accuracy= 0.800\n",
      "Step 28200, Minibatch Loss= 2243.5186, Training Accuracy= 0.740\n",
      "Step 28300, Minibatch Loss= 2494.4272, Training Accuracy= 0.660\n",
      "Step 28400, Minibatch Loss= 1575.7010, Training Accuracy= 0.750\n",
      "Step 28500, Minibatch Loss= 13836.2637, Training Accuracy= 0.640\n",
      "Step 28600, Minibatch Loss= 2161.6404, Training Accuracy= 0.680\n",
      "Step 28700, Minibatch Loss= 3453.2686, Training Accuracy= 0.620\n",
      "Step 28800, Minibatch Loss= 6352.4951, Training Accuracy= 0.520\n",
      "Step 28900, Minibatch Loss= 5654.9336, Training Accuracy= 0.710\n",
      "Step 29000, Minibatch Loss= 4508.4185, Training Accuracy= 0.700\n",
      "Step 29100, Minibatch Loss= 4544.3340, Training Accuracy= 0.570\n",
      "Step 29200, Minibatch Loss= 1085.2820, Training Accuracy= 0.820\n",
      "Step 29300, Minibatch Loss= 1165.1696, Training Accuracy= 0.750\n",
      "Step 29400, Minibatch Loss= 3098.5122, Training Accuracy= 0.700\n",
      "Step 29500, Minibatch Loss= 8659.6660, Training Accuracy= 0.530\n",
      "Step 29600, Minibatch Loss= 9531.8203, Training Accuracy= 0.660\n",
      "Step 29700, Minibatch Loss= 1102.7305, Training Accuracy= 0.770\n",
      "Step 29800, Minibatch Loss= 5418.4312, Training Accuracy= 0.610\n",
      "Step 29900, Minibatch Loss= 5837.6138, Training Accuracy= 0.730\n",
      "Step 30000, Minibatch Loss= 3797.4890, Training Accuracy= 0.700\n",
      "Step 30100, Minibatch Loss= 3846.1699, Training Accuracy= 0.690\n",
      "Step 30200, Minibatch Loss= 1297.4146, Training Accuracy= 0.770\n",
      "Step 30300, Minibatch Loss= 3748.0669, Training Accuracy= 0.670\n",
      "Step 30400, Minibatch Loss= 2440.9482, Training Accuracy= 0.710\n",
      "Step 30500, Minibatch Loss= 1342.5760, Training Accuracy= 0.840\n",
      "Step 30600, Minibatch Loss= 8701.5908, Training Accuracy= 0.510\n",
      "Step 30700, Minibatch Loss= 4648.2783, Training Accuracy= 0.720\n",
      "Step 30800, Minibatch Loss= 1755.4532, Training Accuracy= 0.690\n",
      "Step 30900, Minibatch Loss= 958.0952, Training Accuracy= 0.830\n",
      "Step 31000, Minibatch Loss= 1368.7677, Training Accuracy= 0.800\n",
      "Step 31100, Minibatch Loss= 5419.4238, Training Accuracy= 0.720\n",
      "Step 31200, Minibatch Loss= 1259.7698, Training Accuracy= 0.770\n",
      "Step 31300, Minibatch Loss= 6231.9785, Training Accuracy= 0.580\n",
      "Step 31400, Minibatch Loss= 2237.5122, Training Accuracy= 0.700\n",
      "Step 31500, Minibatch Loss= 6456.6699, Training Accuracy= 0.760\n",
      "Step 31600, Minibatch Loss= 1287.6254, Training Accuracy= 0.770\n",
      "Step 31700, Minibatch Loss= 1826.7249, Training Accuracy= 0.700\n",
      "Step 31800, Minibatch Loss= 1910.5867, Training Accuracy= 0.700\n",
      "Step 31900, Minibatch Loss= 23806.3691, Training Accuracy= 0.700\n",
      "Step 32000, Minibatch Loss= 13392.2773, Training Accuracy= 0.730\n",
      "Step 32100, Minibatch Loss= 4103.0977, Training Accuracy= 0.700\n",
      "Step 32200, Minibatch Loss= 2758.4094, Training Accuracy= 0.700\n",
      "Step 32300, Minibatch Loss= 2733.0125, Training Accuracy= 0.740\n",
      "Step 32400, Minibatch Loss= 4271.7363, Training Accuracy= 0.640\n",
      "Step 32500, Minibatch Loss= 1671.3553, Training Accuracy= 0.720\n",
      "Step 32600, Minibatch Loss= 1315.7574, Training Accuracy= 0.790\n",
      "Step 32700, Minibatch Loss= 13949.6953, Training Accuracy= 0.690\n",
      "Step 32800, Minibatch Loss= 2297.4150, Training Accuracy= 0.620\n",
      "Step 32900, Minibatch Loss= 6782.2451, Training Accuracy= 0.720\n",
      "Step 33000, Minibatch Loss= 3235.1162, Training Accuracy= 0.710\n",
      "Step 33100, Minibatch Loss= 1699.7173, Training Accuracy= 0.730\n",
      "Step 33200, Minibatch Loss= 2663.5288, Training Accuracy= 0.630\n",
      "Step 33300, Minibatch Loss= 3047.3918, Training Accuracy= 0.740\n",
      "Step 33400, Minibatch Loss= 3027.8853, Training Accuracy= 0.710\n",
      "Step 33500, Minibatch Loss= 2731.2068, Training Accuracy= 0.700\n",
      "Step 33600, Minibatch Loss= 1154.5980, Training Accuracy= 0.780\n",
      "Step 33700, Minibatch Loss= 1529.2000, Training Accuracy= 0.740\n",
      "Step 33800, Minibatch Loss= 1398.7373, Training Accuracy= 0.780\n",
      "Step 33900, Minibatch Loss= 4418.4561, Training Accuracy= 0.560\n",
      "Step 34000, Minibatch Loss= 3146.1238, Training Accuracy= 0.710\n",
      "Step 34100, Minibatch Loss= 2602.2837, Training Accuracy= 0.650\n",
      "Step 34200, Minibatch Loss= 1729.4442, Training Accuracy= 0.770\n",
      "Step 34300, Minibatch Loss= 3485.5479, Training Accuracy= 0.690\n",
      "Step 34400, Minibatch Loss= 3050.9966, Training Accuracy= 0.730\n",
      "Step 34500, Minibatch Loss= 6414.2529, Training Accuracy= 0.680\n",
      "Step 34600, Minibatch Loss= 1442.7623, Training Accuracy= 0.820\n",
      "Step 34700, Minibatch Loss= 14754.8291, Training Accuracy= 0.660\n",
      "Step 34800, Minibatch Loss= 4985.0830, Training Accuracy= 0.640\n",
      "Step 34900, Minibatch Loss= 6149.0269, Training Accuracy= 0.770\n",
      "Step 35000, Minibatch Loss= 3653.5164, Training Accuracy= 0.730\n",
      "Step 35100, Minibatch Loss= 3754.5679, Training Accuracy= 0.690\n",
      "Step 35200, Minibatch Loss= 7151.3330, Training Accuracy= 0.750\n",
      "Step 35300, Minibatch Loss= 3605.9468, Training Accuracy= 0.760\n",
      "Step 35400, Minibatch Loss= 6374.4233, Training Accuracy= 0.620\n",
      "Step 35500, Minibatch Loss= 1706.7133, Training Accuracy= 0.780\n",
      "Step 35600, Minibatch Loss= 2049.1458, Training Accuracy= 0.690\n",
      "Step 35700, Minibatch Loss= 5270.7925, Training Accuracy= 0.740\n",
      "Step 35800, Minibatch Loss= 6350.3936, Training Accuracy= 0.590\n",
      "Step 35900, Minibatch Loss= 1750.2646, Training Accuracy= 0.750\n",
      "Step 36000, Minibatch Loss= 10202.6035, Training Accuracy= 0.730\n",
      "Step 36100, Minibatch Loss= 5949.5283, Training Accuracy= 0.760\n",
      "Step 36200, Minibatch Loss= 1633.8187, Training Accuracy= 0.790\n",
      "Step 36300, Minibatch Loss= 3264.4487, Training Accuracy= 0.580\n",
      "Step 36400, Minibatch Loss= 2191.3218, Training Accuracy= 0.630\n",
      "Step 36500, Minibatch Loss= 9572.5312, Training Accuracy= 0.690\n",
      "Step 36600, Minibatch Loss= 1670.9817, Training Accuracy= 0.780\n",
      "Step 36700, Minibatch Loss= 16940.0645, Training Accuracy= 0.430\n",
      "Step 36800, Minibatch Loss= 1688.0199, Training Accuracy= 0.740\n",
      "Step 36900, Minibatch Loss= 6817.7251, Training Accuracy= 0.530\n",
      "Step 37000, Minibatch Loss= 9499.9258, Training Accuracy= 0.630\n",
      "Step 37100, Minibatch Loss= 1259.7002, Training Accuracy= 0.780\n",
      "Step 37200, Minibatch Loss= 5699.0244, Training Accuracy= 0.610\n",
      "Step 37300, Minibatch Loss= 1042.3774, Training Accuracy= 0.810\n",
      "Step 37400, Minibatch Loss= 5271.4390, Training Accuracy= 0.720\n",
      "Step 37500, Minibatch Loss= 7047.1387, Training Accuracy= 0.520\n",
      "Step 37600, Minibatch Loss= 1599.7727, Training Accuracy= 0.730\n",
      "Step 37700, Minibatch Loss= 4824.9312, Training Accuracy= 0.680\n",
      "Step 37800, Minibatch Loss= 3068.6443, Training Accuracy= 0.660\n",
      "Step 37900, Minibatch Loss= 4809.2612, Training Accuracy= 0.570\n",
      "Step 38000, Minibatch Loss= 1368.3265, Training Accuracy= 0.800\n",
      "Step 38100, Minibatch Loss= 1004.0944, Training Accuracy= 0.750\n",
      "Step 38200, Minibatch Loss= 1732.7178, Training Accuracy= 0.800\n",
      "Step 38300, Minibatch Loss= 3526.4495, Training Accuracy= 0.600\n",
      "Step 38400, Minibatch Loss= 1415.5363, Training Accuracy= 0.760\n",
      "Step 38500, Minibatch Loss= 6730.6074, Training Accuracy= 0.700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 38600, Minibatch Loss= 5026.7100, Training Accuracy= 0.700\n",
      "Step 38700, Minibatch Loss= 4404.1914, Training Accuracy= 0.730\n",
      "Step 38800, Minibatch Loss= 3941.0947, Training Accuracy= 0.710\n",
      "Step 38900, Minibatch Loss= 1771.4971, Training Accuracy= 0.730\n",
      "Step 39000, Minibatch Loss= 11896.6680, Training Accuracy= 0.480\n",
      "Step 39100, Minibatch Loss= 1302.8524, Training Accuracy= 0.780\n",
      "Step 39200, Minibatch Loss= 4065.0706, Training Accuracy= 0.620\n",
      "Step 39300, Minibatch Loss= 1490.2064, Training Accuracy= 0.700\n",
      "Step 39400, Minibatch Loss= 3127.0461, Training Accuracy= 0.610\n",
      "Step 39500, Minibatch Loss= 5597.4888, Training Accuracy= 0.580\n",
      "Step 39600, Minibatch Loss= 4656.1445, Training Accuracy= 0.580\n",
      "Step 39700, Minibatch Loss= 5073.2349, Training Accuracy= 0.740\n",
      "Step 39800, Minibatch Loss= 3785.4355, Training Accuracy= 0.650\n",
      "Step 39900, Minibatch Loss= 3540.4272, Training Accuracy= 0.780\n",
      "Step 40000, Minibatch Loss= 8083.3813, Training Accuracy= 0.780\n",
      "Step 40100, Minibatch Loss= 2012.8964, Training Accuracy= 0.690\n",
      "Step 40200, Minibatch Loss= 1670.9587, Training Accuracy= 0.780\n",
      "Step 40300, Minibatch Loss= 3264.4077, Training Accuracy= 0.620\n",
      "Step 40400, Minibatch Loss= 6053.1187, Training Accuracy= 0.570\n",
      "Step 40500, Minibatch Loss= 6160.8730, Training Accuracy= 0.740\n",
      "Step 40600, Minibatch Loss= 1446.5144, Training Accuracy= 0.790\n",
      "Step 40700, Minibatch Loss= 1062.7781, Training Accuracy= 0.760\n",
      "Step 40800, Minibatch Loss= 1425.7379, Training Accuracy= 0.790\n",
      "Step 40900, Minibatch Loss= 4655.3872, Training Accuracy= 0.620\n",
      "Step 41000, Minibatch Loss= 21086.4258, Training Accuracy= 0.690\n",
      "Step 41100, Minibatch Loss= 1968.3673, Training Accuracy= 0.780\n",
      "Step 41200, Minibatch Loss= 2159.1909, Training Accuracy= 0.700\n",
      "Step 41300, Minibatch Loss= 1037.9351, Training Accuracy= 0.780\n",
      "Step 41400, Minibatch Loss= 6041.8970, Training Accuracy= 0.710\n",
      "Step 41500, Minibatch Loss= 1520.2222, Training Accuracy= 0.710\n",
      "Step 41600, Minibatch Loss= 2572.1816, Training Accuracy= 0.700\n",
      "Step 41700, Minibatch Loss= 7351.6226, Training Accuracy= 0.530\n",
      "Step 41800, Minibatch Loss= 1685.8688, Training Accuracy= 0.750\n",
      "Step 41900, Minibatch Loss= 2492.1392, Training Accuracy= 0.680\n",
      "Step 42000, Minibatch Loss= 2835.8423, Training Accuracy= 0.650\n",
      "Step 42100, Minibatch Loss= 6849.2925, Training Accuracy= 0.810\n",
      "Step 42200, Minibatch Loss= 2332.3022, Training Accuracy= 0.670\n",
      "Step 42300, Minibatch Loss= 14114.5801, Training Accuracy= 0.460\n",
      "Step 42400, Minibatch Loss= 2358.1819, Training Accuracy= 0.710\n",
      "Step 42500, Minibatch Loss= 989.6301, Training Accuracy= 0.730\n",
      "Step 42600, Minibatch Loss= 2184.0781, Training Accuracy= 0.730\n",
      "Step 42700, Minibatch Loss= 1164.2065, Training Accuracy= 0.770\n",
      "Step 42800, Minibatch Loss= 2207.6995, Training Accuracy= 0.730\n",
      "Step 42900, Minibatch Loss= 3556.3289, Training Accuracy= 0.790\n",
      "Step 43000, Minibatch Loss= 1859.7258, Training Accuracy= 0.790\n",
      "Step 43100, Minibatch Loss= 2206.0513, Training Accuracy= 0.700\n",
      "Step 43200, Minibatch Loss= 6294.6924, Training Accuracy= 0.570\n",
      "Step 43300, Minibatch Loss= 1054.3922, Training Accuracy= 0.730\n",
      "Step 43400, Minibatch Loss= 2616.1592, Training Accuracy= 0.640\n",
      "Step 43500, Minibatch Loss= 4714.0459, Training Accuracy= 0.710\n",
      "Step 43600, Minibatch Loss= 7823.3042, Training Accuracy= 0.470\n",
      "Step 43700, Minibatch Loss= 1099.7253, Training Accuracy= 0.750\n",
      "Step 43800, Minibatch Loss= 4926.1523, Training Accuracy= 0.640\n",
      "Step 43900, Minibatch Loss= 9451.4531, Training Accuracy= 0.730\n",
      "Step 44000, Minibatch Loss= 1033.8833, Training Accuracy= 0.810\n",
      "Step 44100, Minibatch Loss= 12203.7764, Training Accuracy= 0.710\n",
      "Step 44200, Minibatch Loss= 1807.8640, Training Accuracy= 0.690\n",
      "Step 44300, Minibatch Loss= 4921.7905, Training Accuracy= 0.640\n",
      "Step 44400, Minibatch Loss= 4118.6733, Training Accuracy= 0.770\n",
      "Step 44500, Minibatch Loss= 1998.3875, Training Accuracy= 0.740\n",
      "Step 44600, Minibatch Loss= 8329.8867, Training Accuracy= 0.500\n",
      "Step 44700, Minibatch Loss= 3045.6956, Training Accuracy= 0.650\n",
      "Step 44800, Minibatch Loss= 6949.4316, Training Accuracy= 0.710\n",
      "Step 44900, Minibatch Loss= 3128.0649, Training Accuracy= 0.650\n",
      "Step 45000, Minibatch Loss= 1838.6534, Training Accuracy= 0.770\n",
      "Step 45100, Minibatch Loss= 8532.7998, Training Accuracy= 0.660\n",
      "Step 45200, Minibatch Loss= 1921.0881, Training Accuracy= 0.660\n",
      "Step 45300, Minibatch Loss= 2807.1460, Training Accuracy= 0.640\n",
      "Step 45400, Minibatch Loss= 1103.9497, Training Accuracy= 0.800\n",
      "Step 45500, Minibatch Loss= 3393.5588, Training Accuracy= 0.790\n",
      "Step 45600, Minibatch Loss= 2212.8025, Training Accuracy= 0.710\n",
      "Step 45700, Minibatch Loss= 9162.8184, Training Accuracy= 0.660\n",
      "Step 45800, Minibatch Loss= 5083.9087, Training Accuracy= 0.670\n",
      "Step 45900, Minibatch Loss= 2651.7949, Training Accuracy= 0.790\n",
      "Step 46000, Minibatch Loss= 2054.7646, Training Accuracy= 0.710\n",
      "Step 46100, Minibatch Loss= 1609.9413, Training Accuracy= 0.760\n",
      "Step 46200, Minibatch Loss= 2862.5000, Training Accuracy= 0.770\n",
      "Step 46300, Minibatch Loss= 1101.5170, Training Accuracy= 0.630\n",
      "Step 46400, Minibatch Loss= 6790.3657, Training Accuracy= 0.730\n",
      "Step 46500, Minibatch Loss= 3597.5901, Training Accuracy= 0.760\n",
      "Step 46600, Minibatch Loss= 2752.8486, Training Accuracy= 0.720\n",
      "Step 46700, Minibatch Loss= 3033.9724, Training Accuracy= 0.750\n",
      "Step 46800, Minibatch Loss= 7924.7930, Training Accuracy= 0.750\n",
      "Step 46900, Minibatch Loss= 2129.3481, Training Accuracy= 0.680\n",
      "Step 47000, Minibatch Loss= 10090.4639, Training Accuracy= 0.520\n",
      "Step 47100, Minibatch Loss= 11917.5664, Training Accuracy= 0.440\n",
      "Step 47200, Minibatch Loss= 1326.7993, Training Accuracy= 0.700\n",
      "Step 47300, Minibatch Loss= 3780.6248, Training Accuracy= 0.770\n",
      "Step 47400, Minibatch Loss= 1395.9666, Training Accuracy= 0.760\n",
      "Step 47500, Minibatch Loss= 1291.9037, Training Accuracy= 0.770\n",
      "Step 47600, Minibatch Loss= 1430.8428, Training Accuracy= 0.720\n",
      "Step 47700, Minibatch Loss= 18274.7109, Training Accuracy= 0.700\n",
      "Step 47800, Minibatch Loss= 1602.8433, Training Accuracy= 0.700\n",
      "Step 47900, Minibatch Loss= 7187.1577, Training Accuracy= 0.610\n",
      "Step 48000, Minibatch Loss= 2346.9795, Training Accuracy= 0.810\n",
      "Step 48100, Minibatch Loss= 1362.0305, Training Accuracy= 0.760\n",
      "Step 48200, Minibatch Loss= 6352.4639, Training Accuracy= 0.690\n",
      "Step 48300, Minibatch Loss= 2573.7432, Training Accuracy= 0.780\n",
      "Step 48400, Minibatch Loss= 1198.0659, Training Accuracy= 0.780\n",
      "Step 48500, Minibatch Loss= 2846.5237, Training Accuracy= 0.620\n",
      "Step 48600, Minibatch Loss= 2173.0293, Training Accuracy= 0.740\n",
      "Step 48700, Minibatch Loss= 11115.0479, Training Accuracy= 0.720\n",
      "Step 48800, Minibatch Loss= 1227.1407, Training Accuracy= 0.800\n",
      "Step 48900, Minibatch Loss= 7864.4731, Training Accuracy= 0.710\n",
      "Step 49000, Minibatch Loss= 916.2213, Training Accuracy= 0.800\n",
      "Step 49100, Minibatch Loss= 931.3339, Training Accuracy= 0.770\n",
      "Step 49200, Minibatch Loss= 1292.8744, Training Accuracy= 0.790\n",
      "Step 49300, Minibatch Loss= 1078.9891, Training Accuracy= 0.820\n",
      "Step 49400, Minibatch Loss= 7332.2427, Training Accuracy= 0.700\n",
      "Step 49500, Minibatch Loss= 4189.9468, Training Accuracy= 0.740\n",
      "Step 49600, Minibatch Loss= 983.6044, Training Accuracy= 0.800\n",
      "Step 49700, Minibatch Loss= 1243.6987, Training Accuracy= 0.780\n",
      "Step 49800, Minibatch Loss= 1891.4019, Training Accuracy= 0.670\n",
      "Step 49900, Minibatch Loss= 1072.9799, Training Accuracy= 0.780\n",
      "Step 50000, Minibatch Loss= 2136.7393, Training Accuracy= 0.720\n",
      "Step 50100, Minibatch Loss= 1170.0713, Training Accuracy= 0.790\n",
      "Step 50200, Minibatch Loss= 835.7307, Training Accuracy= 0.800\n",
      "Step 50300, Minibatch Loss= 1361.8604, Training Accuracy= 0.760\n",
      "Step 50400, Minibatch Loss= 1370.3756, Training Accuracy= 0.750\n",
      "Step 50500, Minibatch Loss= 2949.2803, Training Accuracy= 0.640\n",
      "Step 50600, Minibatch Loss= 1145.6602, Training Accuracy= 0.760\n",
      "Step 50700, Minibatch Loss= 1653.1324, Training Accuracy= 0.720\n",
      "Step 50800, Minibatch Loss= 1210.4387, Training Accuracy= 0.800\n",
      "Step 50900, Minibatch Loss= 4300.4380, Training Accuracy= 0.560\n",
      "Step 51000, Minibatch Loss= 4419.0430, Training Accuracy= 0.650\n",
      "Step 51100, Minibatch Loss= 2115.3916, Training Accuracy= 0.700\n",
      "Step 51200, Minibatch Loss= 1367.3508, Training Accuracy= 0.750\n",
      "Step 51300, Minibatch Loss= 2025.1254, Training Accuracy= 0.650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 51400, Minibatch Loss= 16327.9873, Training Accuracy= 0.410\n",
      "Step 51500, Minibatch Loss= 2739.8730, Training Accuracy= 0.740\n",
      "Step 51600, Minibatch Loss= 1569.3744, Training Accuracy= 0.820\n",
      "Step 51700, Minibatch Loss= 1066.8926, Training Accuracy= 0.760\n",
      "Step 51800, Minibatch Loss= 1112.8453, Training Accuracy= 0.830\n",
      "Step 51900, Minibatch Loss= 1040.6414, Training Accuracy= 0.790\n",
      "Step 52000, Minibatch Loss= 2502.0645, Training Accuracy= 0.730\n",
      "Step 52100, Minibatch Loss= 985.3452, Training Accuracy= 0.720\n",
      "Step 52200, Minibatch Loss= 9413.3564, Training Accuracy= 0.700\n",
      "Step 52300, Minibatch Loss= 1731.7366, Training Accuracy= 0.790\n",
      "Step 52400, Minibatch Loss= 5318.5215, Training Accuracy= 0.510\n",
      "Step 52500, Minibatch Loss= 7568.2524, Training Accuracy= 0.480\n",
      "Step 52600, Minibatch Loss= 2399.4111, Training Accuracy= 0.730\n",
      "Step 52700, Minibatch Loss= 7767.5444, Training Accuracy= 0.530\n",
      "Step 52800, Minibatch Loss= 2259.7246, Training Accuracy= 0.780\n",
      "Step 52900, Minibatch Loss= 4936.8398, Training Accuracy= 0.750\n",
      "Step 53000, Minibatch Loss= 3012.8794, Training Accuracy= 0.680\n",
      "Step 53100, Minibatch Loss= 817.2767, Training Accuracy= 0.800\n",
      "Step 53200, Minibatch Loss= 2267.7097, Training Accuracy= 0.710\n",
      "Step 53300, Minibatch Loss= 4603.6914, Training Accuracy= 0.700\n",
      "Step 53400, Minibatch Loss= 1214.0546, Training Accuracy= 0.770\n",
      "Step 53500, Minibatch Loss= 2799.6257, Training Accuracy= 0.740\n",
      "Step 53600, Minibatch Loss= 849.4989, Training Accuracy= 0.780\n",
      "Step 53700, Minibatch Loss= 774.2519, Training Accuracy= 0.860\n",
      "Step 53800, Minibatch Loss= 7301.0386, Training Accuracy= 0.740\n",
      "Step 53900, Minibatch Loss= 6806.3286, Training Accuracy= 0.730\n",
      "Step 54000, Minibatch Loss= 3690.8513, Training Accuracy= 0.720\n",
      "Step 54100, Minibatch Loss= 6170.0332, Training Accuracy= 0.770\n",
      "Step 54200, Minibatch Loss= 10495.4727, Training Accuracy= 0.720\n",
      "Step 54300, Minibatch Loss= 964.8200, Training Accuracy= 0.840\n",
      "Step 54400, Minibatch Loss= 7854.1875, Training Accuracy= 0.460\n",
      "Step 54500, Minibatch Loss= 2765.9175, Training Accuracy= 0.670\n",
      "Step 54600, Minibatch Loss= 2032.1591, Training Accuracy= 0.740\n",
      "Step 54700, Minibatch Loss= 2101.9736, Training Accuracy= 0.650\n",
      "Step 54800, Minibatch Loss= 1009.0744, Training Accuracy= 0.810\n",
      "Step 54900, Minibatch Loss= 811.2497, Training Accuracy= 0.810\n",
      "Step 55000, Minibatch Loss= 8479.7822, Training Accuracy= 0.750\n",
      "Step 55100, Minibatch Loss= 1342.3483, Training Accuracy= 0.790\n",
      "Step 55200, Minibatch Loss= 3563.9487, Training Accuracy= 0.570\n",
      "Step 55300, Minibatch Loss= 706.0531, Training Accuracy= 0.820\n",
      "Step 55400, Minibatch Loss= 5238.2759, Training Accuracy= 0.710\n",
      "Step 55500, Minibatch Loss= 2206.3765, Training Accuracy= 0.740\n",
      "Step 55600, Minibatch Loss= 3514.3784, Training Accuracy= 0.570\n",
      "Step 55700, Minibatch Loss= 1183.1082, Training Accuracy= 0.750\n",
      "Step 55800, Minibatch Loss= 5256.3374, Training Accuracy= 0.770\n",
      "Step 55900, Minibatch Loss= 2822.4910, Training Accuracy= 0.630\n",
      "Step 56000, Minibatch Loss= 1125.3274, Training Accuracy= 0.770\n",
      "Step 56100, Minibatch Loss= 1178.1073, Training Accuracy= 0.770\n",
      "Step 56200, Minibatch Loss= 6689.2227, Training Accuracy= 0.760\n",
      "Step 56300, Minibatch Loss= 10272.3311, Training Accuracy= 0.460\n",
      "Step 56400, Minibatch Loss= 2169.7754, Training Accuracy= 0.760\n",
      "Step 56500, Minibatch Loss= 2448.1047, Training Accuracy= 0.770\n",
      "Step 56600, Minibatch Loss= 1139.1356, Training Accuracy= 0.740\n",
      "Step 56700, Minibatch Loss= 1775.5319, Training Accuracy= 0.720\n",
      "Step 56800, Minibatch Loss= 4892.9688, Training Accuracy= 0.670\n",
      "Step 56900, Minibatch Loss= 1342.0000, Training Accuracy= 0.780\n",
      "Step 57000, Minibatch Loss= 2893.0188, Training Accuracy= 0.640\n",
      "Step 57100, Minibatch Loss= 3874.4600, Training Accuracy= 0.720\n",
      "Step 57200, Minibatch Loss= 2305.9446, Training Accuracy= 0.740\n",
      "Step 57300, Minibatch Loss= 1793.2657, Training Accuracy= 0.690\n",
      "Step 57400, Minibatch Loss= 1282.0779, Training Accuracy= 0.790\n",
      "Step 57500, Minibatch Loss= 2580.8640, Training Accuracy= 0.610\n",
      "Step 57600, Minibatch Loss= 1955.9047, Training Accuracy= 0.770\n",
      "Step 57700, Minibatch Loss= 1133.2415, Training Accuracy= 0.750\n",
      "Step 57800, Minibatch Loss= 1867.7301, Training Accuracy= 0.670\n",
      "Step 57900, Minibatch Loss= 5190.9336, Training Accuracy= 0.580\n",
      "Step 58000, Minibatch Loss= 5659.9463, Training Accuracy= 0.750\n",
      "Step 58100, Minibatch Loss= 987.4238, Training Accuracy= 0.690\n",
      "Step 58200, Minibatch Loss= 9706.1035, Training Accuracy= 0.710\n",
      "Step 58300, Minibatch Loss= 2890.0969, Training Accuracy= 0.760\n",
      "Step 58400, Minibatch Loss= 6299.6382, Training Accuracy= 0.510\n",
      "Step 58500, Minibatch Loss= 3427.5156, Training Accuracy= 0.730\n",
      "Step 58600, Minibatch Loss= 1645.6328, Training Accuracy= 0.750\n",
      "Step 58700, Minibatch Loss= 3161.8804, Training Accuracy= 0.580\n",
      "Step 58800, Minibatch Loss= 5631.2207, Training Accuracy= 0.560\n",
      "Step 58900, Minibatch Loss= 5994.3970, Training Accuracy= 0.710\n",
      "Step 59000, Minibatch Loss= 1283.1470, Training Accuracy= 0.740\n",
      "Step 59100, Minibatch Loss= 3642.4294, Training Accuracy= 0.770\n",
      "Step 59200, Minibatch Loss= 5940.5186, Training Accuracy= 0.510\n",
      "Step 59300, Minibatch Loss= 5192.3022, Training Accuracy= 0.730\n",
      "Step 59400, Minibatch Loss= 1159.6399, Training Accuracy= 0.740\n",
      "Step 59500, Minibatch Loss= 4597.2871, Training Accuracy= 0.730\n",
      "Step 59600, Minibatch Loss= 1527.3878, Training Accuracy= 0.750\n",
      "Step 59700, Minibatch Loss= 4134.1499, Training Accuracy= 0.610\n",
      "Step 59800, Minibatch Loss= 5912.1289, Training Accuracy= 0.600\n",
      "Step 59900, Minibatch Loss= 892.9697, Training Accuracy= 0.710\n",
      "Step 60000, Minibatch Loss= 1719.0682, Training Accuracy= 0.740\n",
      "Step 60100, Minibatch Loss= 6597.0264, Training Accuracy= 0.680\n",
      "Step 60200, Minibatch Loss= 6262.6108, Training Accuracy= 0.750\n",
      "Step 60300, Minibatch Loss= 1873.1328, Training Accuracy= 0.750\n",
      "Step 60400, Minibatch Loss= 17758.2773, Training Accuracy= 0.440\n",
      "Step 60500, Minibatch Loss= 958.0137, Training Accuracy= 0.780\n",
      "Step 60600, Minibatch Loss= 838.1031, Training Accuracy= 0.810\n",
      "Step 60700, Minibatch Loss= 981.6766, Training Accuracy= 0.770\n",
      "Step 60800, Minibatch Loss= 951.6092, Training Accuracy= 0.760\n",
      "Step 60900, Minibatch Loss= 997.3098, Training Accuracy= 0.800\n",
      "Step 61000, Minibatch Loss= 1710.1084, Training Accuracy= 0.760\n",
      "Step 61100, Minibatch Loss= 1725.9805, Training Accuracy= 0.720\n",
      "Step 61200, Minibatch Loss= 3334.3530, Training Accuracy= 0.670\n",
      "Step 61300, Minibatch Loss= 6335.2812, Training Accuracy= 0.530\n",
      "Step 61400, Minibatch Loss= 1663.4995, Training Accuracy= 0.720\n",
      "Step 61500, Minibatch Loss= 3330.5649, Training Accuracy= 0.640\n",
      "Step 61600, Minibatch Loss= 3823.3228, Training Accuracy= 0.700\n",
      "Step 61700, Minibatch Loss= 2377.4866, Training Accuracy= 0.770\n",
      "Step 61800, Minibatch Loss= 3219.0852, Training Accuracy= 0.770\n",
      "Step 61900, Minibatch Loss= 4970.3311, Training Accuracy= 0.610\n",
      "Step 62000, Minibatch Loss= 1151.5420, Training Accuracy= 0.800\n",
      "Step 62100, Minibatch Loss= 4189.3164, Training Accuracy= 0.730\n",
      "Step 62200, Minibatch Loss= 1915.5671, Training Accuracy= 0.790\n",
      "Step 62300, Minibatch Loss= 4898.9951, Training Accuracy= 0.690\n",
      "Step 62400, Minibatch Loss= 2916.9006, Training Accuracy= 0.680\n",
      "Step 62500, Minibatch Loss= 1107.5774, Training Accuracy= 0.720\n",
      "Step 62600, Minibatch Loss= 1174.1639, Training Accuracy= 0.770\n",
      "Step 62700, Minibatch Loss= 3166.7861, Training Accuracy= 0.720\n",
      "Step 62800, Minibatch Loss= 2905.5232, Training Accuracy= 0.620\n",
      "Step 62900, Minibatch Loss= 8356.1504, Training Accuracy= 0.470\n",
      "Step 63000, Minibatch Loss= 4905.5649, Training Accuracy= 0.730\n",
      "Step 63100, Minibatch Loss= 903.5310, Training Accuracy= 0.830\n",
      "Step 63200, Minibatch Loss= 2355.3357, Training Accuracy= 0.740\n",
      "Step 63300, Minibatch Loss= 2406.2881, Training Accuracy= 0.600\n",
      "Step 63400, Minibatch Loss= 3336.9546, Training Accuracy= 0.680\n",
      "Step 63500, Minibatch Loss= 1619.0529, Training Accuracy= 0.700\n",
      "Step 63600, Minibatch Loss= 1026.4786, Training Accuracy= 0.780\n",
      "Step 63700, Minibatch Loss= 864.3807, Training Accuracy= 0.830\n",
      "Step 63800, Minibatch Loss= 1069.3584, Training Accuracy= 0.780\n",
      "Step 63900, Minibatch Loss= 1754.6478, Training Accuracy= 0.740\n",
      "Step 64000, Minibatch Loss= 5786.2427, Training Accuracy= 0.520\n",
      "Step 64100, Minibatch Loss= 2629.1897, Training Accuracy= 0.760\n",
      "Step 64200, Minibatch Loss= 831.5916, Training Accuracy= 0.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 64300, Minibatch Loss= 2399.2773, Training Accuracy= 0.760\n",
      "Step 64400, Minibatch Loss= 1057.5408, Training Accuracy= 0.740\n",
      "Step 64500, Minibatch Loss= 1089.7703, Training Accuracy= 0.770\n",
      "Step 64600, Minibatch Loss= 2029.8258, Training Accuracy= 0.710\n",
      "Step 64700, Minibatch Loss= 1026.1776, Training Accuracy= 0.730\n",
      "Step 64800, Minibatch Loss= 3266.8181, Training Accuracy= 0.740\n",
      "Step 64900, Minibatch Loss= 11139.9922, Training Accuracy= 0.380\n",
      "Step 65000, Minibatch Loss= 2873.1619, Training Accuracy= 0.650\n",
      "Step 65100, Minibatch Loss= 6514.4048, Training Accuracy= 0.710\n",
      "Step 65200, Minibatch Loss= 3242.8586, Training Accuracy= 0.680\n",
      "Step 65300, Minibatch Loss= 674.9144, Training Accuracy= 0.790\n",
      "Step 65400, Minibatch Loss= 1274.9735, Training Accuracy= 0.830\n",
      "Step 65500, Minibatch Loss= 5388.4082, Training Accuracy= 0.750\n",
      "Step 65600, Minibatch Loss= 4362.9170, Training Accuracy= 0.710\n",
      "Step 65700, Minibatch Loss= 2029.8275, Training Accuracy= 0.660\n",
      "Step 65800, Minibatch Loss= 1449.0406, Training Accuracy= 0.750\n",
      "Step 65900, Minibatch Loss= 11064.6035, Training Accuracy= 0.640\n",
      "Step 66000, Minibatch Loss= 2519.1248, Training Accuracy= 0.710\n",
      "Step 66100, Minibatch Loss= 4469.8970, Training Accuracy= 0.610\n",
      "Step 66200, Minibatch Loss= 1302.2340, Training Accuracy= 0.740\n",
      "Step 66300, Minibatch Loss= 2372.8730, Training Accuracy= 0.800\n",
      "Step 66400, Minibatch Loss= 1062.5173, Training Accuracy= 0.760\n",
      "Step 66500, Minibatch Loss= 3386.3894, Training Accuracy= 0.740\n",
      "Step 66600, Minibatch Loss= 1495.6741, Training Accuracy= 0.700\n",
      "Step 66700, Minibatch Loss= 927.2971, Training Accuracy= 0.760\n",
      "Step 66800, Minibatch Loss= 1708.0780, Training Accuracy= 0.720\n",
      "Step 66900, Minibatch Loss= 1101.7365, Training Accuracy= 0.840\n",
      "Step 67000, Minibatch Loss= 2010.0334, Training Accuracy= 0.720\n",
      "Step 67100, Minibatch Loss= 1608.6456, Training Accuracy= 0.740\n",
      "Step 67200, Minibatch Loss= 4791.2505, Training Accuracy= 0.710\n",
      "Step 67300, Minibatch Loss= 10329.7998, Training Accuracy= 0.500\n",
      "Step 67400, Minibatch Loss= 2440.8096, Training Accuracy= 0.670\n",
      "Step 67500, Minibatch Loss= 1179.2775, Training Accuracy= 0.740\n",
      "Step 67600, Minibatch Loss= 11237.7598, Training Accuracy= 0.460\n",
      "Step 67700, Minibatch Loss= 1553.5479, Training Accuracy= 0.750\n",
      "Step 67800, Minibatch Loss= 1578.5894, Training Accuracy= 0.730\n",
      "Step 67900, Minibatch Loss= 1020.0435, Training Accuracy= 0.870\n",
      "Step 68000, Minibatch Loss= 3414.5781, Training Accuracy= 0.620\n",
      "Step 68100, Minibatch Loss= 1446.1140, Training Accuracy= 0.760\n",
      "Step 68200, Minibatch Loss= 1020.1116, Training Accuracy= 0.810\n",
      "Step 68300, Minibatch Loss= 1224.9658, Training Accuracy= 0.790\n",
      "Step 68400, Minibatch Loss= 3927.2188, Training Accuracy= 0.770\n",
      "Step 68500, Minibatch Loss= 2487.0430, Training Accuracy= 0.720\n",
      "Step 68600, Minibatch Loss= 2972.5625, Training Accuracy= 0.610\n",
      "Step 68700, Minibatch Loss= 761.9401, Training Accuracy= 0.800\n",
      "Step 68800, Minibatch Loss= 2007.1128, Training Accuracy= 0.770\n",
      "Step 68900, Minibatch Loss= 688.5472, Training Accuracy= 0.850\n",
      "Step 69000, Minibatch Loss= 2966.0312, Training Accuracy= 0.730\n",
      "Step 69100, Minibatch Loss= 2604.4087, Training Accuracy= 0.570\n",
      "Step 69200, Minibatch Loss= 1133.7292, Training Accuracy= 0.740\n",
      "Step 69300, Minibatch Loss= 1153.9945, Training Accuracy= 0.720\n",
      "Step 69400, Minibatch Loss= 2687.4177, Training Accuracy= 0.690\n",
      "Step 69500, Minibatch Loss= 2109.1604, Training Accuracy= 0.730\n",
      "Step 69600, Minibatch Loss= 1397.7292, Training Accuracy= 0.770\n",
      "Step 69700, Minibatch Loss= 1303.1899, Training Accuracy= 0.720\n",
      "Step 69800, Minibatch Loss= 10564.5576, Training Accuracy= 0.650\n",
      "Step 69900, Minibatch Loss= 2634.0149, Training Accuracy= 0.780\n",
      "Step 70000, Minibatch Loss= 7087.6411, Training Accuracy= 0.510\n",
      "Step 70100, Minibatch Loss= 2845.8860, Training Accuracy= 0.770\n",
      "Step 70200, Minibatch Loss= 3109.3818, Training Accuracy= 0.830\n",
      "Step 70300, Minibatch Loss= 2147.8318, Training Accuracy= 0.680\n",
      "Step 70400, Minibatch Loss= 1314.4984, Training Accuracy= 0.750\n",
      "Step 70500, Minibatch Loss= 871.5611, Training Accuracy= 0.820\n",
      "Step 70600, Minibatch Loss= 9022.9727, Training Accuracy= 0.690\n",
      "Step 70700, Minibatch Loss= 911.2299, Training Accuracy= 0.810\n",
      "Step 70800, Minibatch Loss= 3240.8081, Training Accuracy= 0.610\n",
      "Step 70900, Minibatch Loss= 1001.2770, Training Accuracy= 0.800\n",
      "Step 71000, Minibatch Loss= 3188.6418, Training Accuracy= 0.560\n",
      "Step 71100, Minibatch Loss= 923.6458, Training Accuracy= 0.840\n",
      "Step 71200, Minibatch Loss= 884.2942, Training Accuracy= 0.830\n",
      "Step 71300, Minibatch Loss= 1736.2284, Training Accuracy= 0.740\n",
      "Step 71400, Minibatch Loss= 5273.6689, Training Accuracy= 0.580\n",
      "Step 71500, Minibatch Loss= 1292.5673, Training Accuracy= 0.750\n",
      "Step 71600, Minibatch Loss= 2132.3596, Training Accuracy= 0.640\n",
      "Step 71700, Minibatch Loss= 1490.4399, Training Accuracy= 0.710\n",
      "Step 71800, Minibatch Loss= 1754.4993, Training Accuracy= 0.810\n",
      "Step 71900, Minibatch Loss= 2153.1045, Training Accuracy= 0.710\n",
      "Step 72000, Minibatch Loss= 5766.8237, Training Accuracy= 0.680\n",
      "Step 72100, Minibatch Loss= 1649.5995, Training Accuracy= 0.680\n",
      "Step 72200, Minibatch Loss= 5096.0396, Training Accuracy= 0.740\n",
      "Step 72300, Minibatch Loss= 2847.0164, Training Accuracy= 0.680\n",
      "Step 72400, Minibatch Loss= 1116.2202, Training Accuracy= 0.750\n",
      "Step 72500, Minibatch Loss= 1711.2177, Training Accuracy= 0.780\n",
      "Step 72600, Minibatch Loss= 2207.0020, Training Accuracy= 0.770\n",
      "Step 72700, Minibatch Loss= 2789.7454, Training Accuracy= 0.760\n",
      "Step 72800, Minibatch Loss= 806.2594, Training Accuracy= 0.770\n",
      "Step 72900, Minibatch Loss= 865.4899, Training Accuracy= 0.770\n",
      "Step 73000, Minibatch Loss= 5413.0562, Training Accuracy= 0.680\n",
      "Step 73100, Minibatch Loss= 2718.7576, Training Accuracy= 0.770\n",
      "Step 73200, Minibatch Loss= 989.1810, Training Accuracy= 0.790\n",
      "Step 73300, Minibatch Loss= 6190.6860, Training Accuracy= 0.490\n",
      "Step 73400, Minibatch Loss= 2724.8416, Training Accuracy= 0.660\n",
      "Step 73500, Minibatch Loss= 2378.6282, Training Accuracy= 0.730\n",
      "Step 73600, Minibatch Loss= 780.6908, Training Accuracy= 0.780\n",
      "Step 73700, Minibatch Loss= 6048.5317, Training Accuracy= 0.520\n",
      "Step 73800, Minibatch Loss= 2202.3215, Training Accuracy= 0.730\n",
      "Step 73900, Minibatch Loss= 1870.3608, Training Accuracy= 0.720\n",
      "Step 74000, Minibatch Loss= 1364.6831, Training Accuracy= 0.840\n",
      "Step 74100, Minibatch Loss= 611.9156, Training Accuracy= 0.830\n",
      "Step 74200, Minibatch Loss= 913.1227, Training Accuracy= 0.770\n",
      "Step 74300, Minibatch Loss= 3960.7610, Training Accuracy= 0.630\n",
      "Step 74400, Minibatch Loss= 1407.0383, Training Accuracy= 0.810\n",
      "Step 74500, Minibatch Loss= 4598.4878, Training Accuracy= 0.750\n",
      "Step 74600, Minibatch Loss= 5008.8799, Training Accuracy= 0.590\n",
      "Step 74700, Minibatch Loss= 800.1323, Training Accuracy= 0.840\n",
      "Step 74800, Minibatch Loss= 4632.3594, Training Accuracy= 0.720\n",
      "Step 74900, Minibatch Loss= 3779.3450, Training Accuracy= 0.730\n",
      "Step 75000, Minibatch Loss= 3274.5537, Training Accuracy= 0.620\n",
      "Step 75100, Minibatch Loss= 4803.9004, Training Accuracy= 0.700\n",
      "Step 75200, Minibatch Loss= 1025.6918, Training Accuracy= 0.750\n",
      "Step 75300, Minibatch Loss= 1076.6162, Training Accuracy= 0.770\n",
      "Step 75400, Minibatch Loss= 2542.9490, Training Accuracy= 0.730\n",
      "Step 75500, Minibatch Loss= 1190.1122, Training Accuracy= 0.750\n",
      "Step 75600, Minibatch Loss= 2981.3044, Training Accuracy= 0.750\n",
      "Step 75700, Minibatch Loss= 2022.1412, Training Accuracy= 0.740\n",
      "Step 75800, Minibatch Loss= 1015.1822, Training Accuracy= 0.750\n",
      "Step 75900, Minibatch Loss= 6683.6201, Training Accuracy= 0.480\n",
      "Step 76000, Minibatch Loss= 6970.0396, Training Accuracy= 0.530\n",
      "Step 76100, Minibatch Loss= 1044.3776, Training Accuracy= 0.720\n",
      "Step 76200, Minibatch Loss= 1063.1403, Training Accuracy= 0.770\n",
      "Step 76300, Minibatch Loss= 657.0355, Training Accuracy= 0.830\n",
      "Step 76400, Minibatch Loss= 4378.3579, Training Accuracy= 0.560\n",
      "Step 76500, Minibatch Loss= 6810.4526, Training Accuracy= 0.750\n",
      "Step 76600, Minibatch Loss= 1656.1935, Training Accuracy= 0.670\n",
      "Step 76700, Minibatch Loss= 9558.5391, Training Accuracy= 0.500\n",
      "Step 76800, Minibatch Loss= 597.8875, Training Accuracy= 0.850\n",
      "Step 76900, Minibatch Loss= 5997.1338, Training Accuracy= 0.510\n",
      "Step 77000, Minibatch Loss= 877.9777, Training Accuracy= 0.740\n",
      "Step 77100, Minibatch Loss= 2897.3245, Training Accuracy= 0.650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 77200, Minibatch Loss= 1285.5526, Training Accuracy= 0.760\n",
      "Step 77300, Minibatch Loss= 1534.4321, Training Accuracy= 0.740\n",
      "Step 77400, Minibatch Loss= 584.8220, Training Accuracy= 0.800\n",
      "Step 77500, Minibatch Loss= 2916.5554, Training Accuracy= 0.740\n",
      "Step 77600, Minibatch Loss= 6965.4043, Training Accuracy= 0.670\n",
      "Step 77700, Minibatch Loss= 4973.1567, Training Accuracy= 0.750\n",
      "Step 77800, Minibatch Loss= 2401.1760, Training Accuracy= 0.670\n",
      "Step 77900, Minibatch Loss= 5856.0288, Training Accuracy= 0.520\n",
      "Step 78000, Minibatch Loss= 6320.7358, Training Accuracy= 0.760\n",
      "Step 78100, Minibatch Loss= 1197.7183, Training Accuracy= 0.830\n",
      "Step 78200, Minibatch Loss= 1986.2089, Training Accuracy= 0.700\n",
      "Step 78300, Minibatch Loss= 786.0383, Training Accuracy= 0.860\n",
      "Step 78400, Minibatch Loss= 2882.7312, Training Accuracy= 0.570\n",
      "Step 78500, Minibatch Loss= 6479.7417, Training Accuracy= 0.680\n",
      "Step 78600, Minibatch Loss= 2055.1689, Training Accuracy= 0.730\n",
      "Step 78700, Minibatch Loss= 7776.8730, Training Accuracy= 0.420\n",
      "Step 78800, Minibatch Loss= 969.6500, Training Accuracy= 0.800\n",
      "Step 78900, Minibatch Loss= 2167.4387, Training Accuracy= 0.660\n",
      "Step 79000, Minibatch Loss= 621.6434, Training Accuracy= 0.860\n",
      "Step 79100, Minibatch Loss= 1622.9000, Training Accuracy= 0.690\n",
      "Step 79200, Minibatch Loss= 7879.4951, Training Accuracy= 0.660\n",
      "Step 79300, Minibatch Loss= 4885.1079, Training Accuracy= 0.720\n",
      "Step 79400, Minibatch Loss= 1898.5714, Training Accuracy= 0.820\n",
      "Step 79500, Minibatch Loss= 7665.4399, Training Accuracy= 0.480\n",
      "Step 79600, Minibatch Loss= 4763.6943, Training Accuracy= 0.740\n",
      "Step 79700, Minibatch Loss= 4728.9033, Training Accuracy= 0.750\n",
      "Step 79800, Minibatch Loss= 3383.9568, Training Accuracy= 0.690\n",
      "Step 79900, Minibatch Loss= 955.9102, Training Accuracy= 0.780\n",
      "Step 80000, Minibatch Loss= 4370.6826, Training Accuracy= 0.600\n",
      "Step 80100, Minibatch Loss= 2788.7800, Training Accuracy= 0.590\n",
      "Step 80200, Minibatch Loss= 755.6786, Training Accuracy= 0.760\n",
      "Step 80300, Minibatch Loss= 13269.6201, Training Accuracy= 0.380\n",
      "Step 80400, Minibatch Loss= 8114.4062, Training Accuracy= 0.710\n",
      "Step 80500, Minibatch Loss= 3129.7722, Training Accuracy= 0.760\n",
      "Step 80600, Minibatch Loss= 1478.4851, Training Accuracy= 0.650\n",
      "Step 80700, Minibatch Loss= 1222.1202, Training Accuracy= 0.750\n",
      "Step 80800, Minibatch Loss= 1733.1974, Training Accuracy= 0.760\n",
      "Step 80900, Minibatch Loss= 2381.6204, Training Accuracy= 0.810\n",
      "Step 81000, Minibatch Loss= 604.4126, Training Accuracy= 0.840\n",
      "Step 81100, Minibatch Loss= 1003.1328, Training Accuracy= 0.810\n",
      "Step 81200, Minibatch Loss= 3768.6018, Training Accuracy= 0.590\n",
      "Step 81300, Minibatch Loss= 2698.7688, Training Accuracy= 0.750\n",
      "Step 81400, Minibatch Loss= 2989.1318, Training Accuracy= 0.740\n",
      "Step 81500, Minibatch Loss= 560.0862, Training Accuracy= 0.770\n",
      "Step 81600, Minibatch Loss= 4654.7671, Training Accuracy= 0.560\n",
      "Step 81700, Minibatch Loss= 4501.6030, Training Accuracy= 0.720\n",
      "Step 81800, Minibatch Loss= 1937.1847, Training Accuracy= 0.670\n",
      "Step 81900, Minibatch Loss= 1269.5939, Training Accuracy= 0.810\n",
      "Step 82000, Minibatch Loss= 3033.7690, Training Accuracy= 0.670\n",
      "Step 82100, Minibatch Loss= 1605.3247, Training Accuracy= 0.760\n",
      "Step 82200, Minibatch Loss= 5008.7188, Training Accuracy= 0.690\n",
      "Step 82300, Minibatch Loss= 1971.0675, Training Accuracy= 0.750\n",
      "Step 82400, Minibatch Loss= 4683.7505, Training Accuracy= 0.700\n",
      "Step 82500, Minibatch Loss= 2789.7581, Training Accuracy= 0.670\n",
      "Step 82600, Minibatch Loss= 5771.6987, Training Accuracy= 0.580\n",
      "Step 82700, Minibatch Loss= 2292.4473, Training Accuracy= 0.700\n",
      "Step 82800, Minibatch Loss= 948.3720, Training Accuracy= 0.810\n",
      "Step 82900, Minibatch Loss= 981.6869, Training Accuracy= 0.760\n",
      "Step 83000, Minibatch Loss= 1044.6052, Training Accuracy= 0.780\n",
      "Step 83100, Minibatch Loss= 5997.0645, Training Accuracy= 0.810\n",
      "Step 83200, Minibatch Loss= 2944.8145, Training Accuracy= 0.590\n",
      "Step 83300, Minibatch Loss= 1465.8226, Training Accuracy= 0.770\n",
      "Step 83400, Minibatch Loss= 884.5966, Training Accuracy= 0.750\n",
      "Step 83500, Minibatch Loss= 971.1650, Training Accuracy= 0.760\n",
      "Step 83600, Minibatch Loss= 3691.4624, Training Accuracy= 0.560\n",
      "Step 83700, Minibatch Loss= 4340.2734, Training Accuracy= 0.570\n",
      "Step 83800, Minibatch Loss= 9466.2744, Training Accuracy= 0.550\n",
      "Step 83900, Minibatch Loss= 1262.0610, Training Accuracy= 0.740\n",
      "Step 84000, Minibatch Loss= 4243.0967, Training Accuracy= 0.730\n",
      "Step 84100, Minibatch Loss= 1541.6637, Training Accuracy= 0.670\n",
      "Step 84200, Minibatch Loss= 1113.2538, Training Accuracy= 0.750\n",
      "Step 84300, Minibatch Loss= 3221.9187, Training Accuracy= 0.740\n",
      "Step 84400, Minibatch Loss= 2006.6680, Training Accuracy= 0.820\n",
      "Step 84500, Minibatch Loss= 2516.6414, Training Accuracy= 0.580\n",
      "Step 84600, Minibatch Loss= 1698.2538, Training Accuracy= 0.740\n",
      "Step 84700, Minibatch Loss= 1843.5071, Training Accuracy= 0.650\n",
      "Step 84800, Minibatch Loss= 812.8672, Training Accuracy= 0.800\n",
      "Step 84900, Minibatch Loss= 5494.2969, Training Accuracy= 0.480\n",
      "Step 85000, Minibatch Loss= 2454.4065, Training Accuracy= 0.800\n",
      "Step 85100, Minibatch Loss= 2052.3591, Training Accuracy= 0.620\n",
      "Step 85200, Minibatch Loss= 813.5204, Training Accuracy= 0.790\n",
      "Step 85300, Minibatch Loss= 3099.1257, Training Accuracy= 0.810\n",
      "Step 85400, Minibatch Loss= 6158.6611, Training Accuracy= 0.780\n",
      "Step 85500, Minibatch Loss= 1799.7701, Training Accuracy= 0.740\n",
      "Step 85600, Minibatch Loss= 2913.8281, Training Accuracy= 0.750\n",
      "Step 85700, Minibatch Loss= 865.6616, Training Accuracy= 0.700\n",
      "Step 85800, Minibatch Loss= 1817.3673, Training Accuracy= 0.720\n",
      "Step 85900, Minibatch Loss= 644.2296, Training Accuracy= 0.790\n",
      "Step 86000, Minibatch Loss= 3552.3171, Training Accuracy= 0.630\n",
      "Step 86100, Minibatch Loss= 1629.3981, Training Accuracy= 0.750\n",
      "Step 86200, Minibatch Loss= 2640.8596, Training Accuracy= 0.750\n",
      "Step 86300, Minibatch Loss= 5742.0312, Training Accuracy= 0.730\n",
      "Step 86400, Minibatch Loss= 3384.4810, Training Accuracy= 0.640\n",
      "Step 86500, Minibatch Loss= 1819.6868, Training Accuracy= 0.770\n",
      "Step 86600, Minibatch Loss= 2337.0964, Training Accuracy= 0.710\n",
      "Step 86700, Minibatch Loss= 2493.6924, Training Accuracy= 0.670\n",
      "Step 86800, Minibatch Loss= 1316.5685, Training Accuracy= 0.730\n",
      "Step 86900, Minibatch Loss= 1524.5001, Training Accuracy= 0.740\n",
      "Step 87000, Minibatch Loss= 1479.9304, Training Accuracy= 0.730\n",
      "Step 87100, Minibatch Loss= 1049.3818, Training Accuracy= 0.820\n",
      "Step 87200, Minibatch Loss= 3541.5984, Training Accuracy= 0.620\n",
      "Step 87300, Minibatch Loss= 9198.8477, Training Accuracy= 0.380\n",
      "Step 87400, Minibatch Loss= 937.9886, Training Accuracy= 0.740\n",
      "Step 87500, Minibatch Loss= 720.8861, Training Accuracy= 0.750\n",
      "Step 87600, Minibatch Loss= 5681.7324, Training Accuracy= 0.530\n",
      "Step 87700, Minibatch Loss= 2156.0911, Training Accuracy= 0.660\n",
      "Step 87800, Minibatch Loss= 1967.0153, Training Accuracy= 0.780\n",
      "Step 87900, Minibatch Loss= 4784.8818, Training Accuracy= 0.800\n",
      "Step 88000, Minibatch Loss= 8568.2354, Training Accuracy= 0.480\n",
      "Step 88100, Minibatch Loss= 1979.2234, Training Accuracy= 0.810\n",
      "Step 88200, Minibatch Loss= 8583.7148, Training Accuracy= 0.460\n",
      "Step 88300, Minibatch Loss= 572.3223, Training Accuracy= 0.790\n",
      "Step 88400, Minibatch Loss= 757.6978, Training Accuracy= 0.800\n",
      "Step 88500, Minibatch Loss= 1154.0468, Training Accuracy= 0.640\n",
      "Step 88600, Minibatch Loss= 2129.2705, Training Accuracy= 0.670\n",
      "Step 88700, Minibatch Loss= 12040.3037, Training Accuracy= 0.700\n",
      "Step 88800, Minibatch Loss= 4129.7368, Training Accuracy= 0.620\n",
      "Step 88900, Minibatch Loss= 1043.5237, Training Accuracy= 0.790\n",
      "Step 89000, Minibatch Loss= 5417.2627, Training Accuracy= 0.720\n",
      "Step 89100, Minibatch Loss= 3343.4424, Training Accuracy= 0.780\n",
      "Step 89200, Minibatch Loss= 865.8080, Training Accuracy= 0.750\n",
      "Step 89300, Minibatch Loss= 593.4039, Training Accuracy= 0.760\n",
      "Step 89400, Minibatch Loss= 3592.2388, Training Accuracy= 0.520\n",
      "Step 89500, Minibatch Loss= 1741.6422, Training Accuracy= 0.760\n",
      "Step 89600, Minibatch Loss= 932.9308, Training Accuracy= 0.790\n",
      "Step 89700, Minibatch Loss= 3763.2944, Training Accuracy= 0.570\n",
      "Step 89800, Minibatch Loss= 774.1567, Training Accuracy= 0.830\n",
      "Step 89900, Minibatch Loss= 1167.1528, Training Accuracy= 0.800\n",
      "Step 90000, Minibatch Loss= 7521.2476, Training Accuracy= 0.730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90100, Minibatch Loss= 10037.2783, Training Accuracy= 0.450\n",
      "Step 90200, Minibatch Loss= 441.2373, Training Accuracy= 0.840\n",
      "Step 90300, Minibatch Loss= 4077.4062, Training Accuracy= 0.710\n",
      "Step 90400, Minibatch Loss= 2211.0488, Training Accuracy= 0.680\n",
      "Step 90500, Minibatch Loss= 2475.9900, Training Accuracy= 0.790\n",
      "Step 90600, Minibatch Loss= 2522.4805, Training Accuracy= 0.670\n",
      "Step 90700, Minibatch Loss= 3208.7732, Training Accuracy= 0.720\n",
      "Step 90800, Minibatch Loss= 2391.6201, Training Accuracy= 0.650\n",
      "Step 90900, Minibatch Loss= 972.2650, Training Accuracy= 0.700\n",
      "Step 91000, Minibatch Loss= 1069.6006, Training Accuracy= 0.720\n",
      "Step 91100, Minibatch Loss= 6022.4150, Training Accuracy= 0.450\n",
      "Step 91200, Minibatch Loss= 785.8714, Training Accuracy= 0.830\n",
      "Step 91300, Minibatch Loss= 977.6635, Training Accuracy= 0.740\n",
      "Step 91400, Minibatch Loss= 810.0675, Training Accuracy= 0.790\n",
      "Step 91500, Minibatch Loss= 2310.2231, Training Accuracy= 0.580\n",
      "Step 91600, Minibatch Loss= 4195.2358, Training Accuracy= 0.570\n",
      "Step 91700, Minibatch Loss= 3430.2876, Training Accuracy= 0.680\n",
      "Step 91800, Minibatch Loss= 4188.3027, Training Accuracy= 0.550\n",
      "Step 91900, Minibatch Loss= 5899.1748, Training Accuracy= 0.680\n",
      "Step 92000, Minibatch Loss= 1003.9119, Training Accuracy= 0.780\n",
      "Step 92100, Minibatch Loss= 3143.8892, Training Accuracy= 0.730\n",
      "Step 92200, Minibatch Loss= 3437.2007, Training Accuracy= 0.740\n",
      "Step 92300, Minibatch Loss= 5980.6035, Training Accuracy= 0.770\n",
      "Step 92400, Minibatch Loss= 1027.4672, Training Accuracy= 0.740\n",
      "Step 92500, Minibatch Loss= 899.6117, Training Accuracy= 0.780\n",
      "Step 92600, Minibatch Loss= 4110.4702, Training Accuracy= 0.570\n",
      "Step 92700, Minibatch Loss= 8303.7598, Training Accuracy= 0.720\n",
      "Step 92800, Minibatch Loss= 5092.4146, Training Accuracy= 0.480\n",
      "Step 92900, Minibatch Loss= 3986.1182, Training Accuracy= 0.750\n",
      "Step 93000, Minibatch Loss= 625.0153, Training Accuracy= 0.800\n",
      "Step 93100, Minibatch Loss= 1325.2588, Training Accuracy= 0.720\n",
      "Step 93200, Minibatch Loss= 1560.0256, Training Accuracy= 0.760\n",
      "Step 93300, Minibatch Loss= 1206.2670, Training Accuracy= 0.810\n",
      "Step 93400, Minibatch Loss= 1694.7230, Training Accuracy= 0.790\n",
      "Step 93500, Minibatch Loss= 1001.6214, Training Accuracy= 0.710\n",
      "Step 93600, Minibatch Loss= 882.1822, Training Accuracy= 0.780\n",
      "Step 93700, Minibatch Loss= 2979.7642, Training Accuracy= 0.650\n",
      "Step 93800, Minibatch Loss= 1072.3545, Training Accuracy= 0.740\n",
      "Step 93900, Minibatch Loss= 902.7428, Training Accuracy= 0.740\n",
      "Step 94000, Minibatch Loss= 620.7590, Training Accuracy= 0.820\n",
      "Step 94100, Minibatch Loss= 4352.3857, Training Accuracy= 0.770\n",
      "Step 94200, Minibatch Loss= 2709.8806, Training Accuracy= 0.660\n",
      "Step 94300, Minibatch Loss= 652.7838, Training Accuracy= 0.770\n",
      "Step 94400, Minibatch Loss= 898.4442, Training Accuracy= 0.750\n",
      "Step 94500, Minibatch Loss= 732.8262, Training Accuracy= 0.780\n",
      "Step 94600, Minibatch Loss= 6456.8213, Training Accuracy= 0.560\n",
      "Step 94700, Minibatch Loss= 2385.5247, Training Accuracy= 0.750\n",
      "Step 94800, Minibatch Loss= 1277.7981, Training Accuracy= 0.760\n",
      "Step 94900, Minibatch Loss= 1064.2573, Training Accuracy= 0.750\n",
      "Step 95000, Minibatch Loss= 4299.3799, Training Accuracy= 0.560\n",
      "Step 95100, Minibatch Loss= 1202.9788, Training Accuracy= 0.730\n",
      "Step 95200, Minibatch Loss= 3870.3850, Training Accuracy= 0.780\n",
      "Step 95300, Minibatch Loss= 2844.9695, Training Accuracy= 0.710\n",
      "Step 95400, Minibatch Loss= 2920.2385, Training Accuracy= 0.720\n",
      "Step 95500, Minibatch Loss= 1105.4271, Training Accuracy= 0.730\n",
      "Step 95600, Minibatch Loss= 1971.0206, Training Accuracy= 0.740\n",
      "Step 95700, Minibatch Loss= 2844.1426, Training Accuracy= 0.760\n",
      "Step 95800, Minibatch Loss= 1375.6240, Training Accuracy= 0.710\n",
      "Step 95900, Minibatch Loss= 4923.2856, Training Accuracy= 0.700\n",
      "Step 96000, Minibatch Loss= 818.4913, Training Accuracy= 0.790\n",
      "Step 96100, Minibatch Loss= 2173.6128, Training Accuracy= 0.690\n",
      "Step 96200, Minibatch Loss= 2003.0128, Training Accuracy= 0.810\n",
      "Step 96300, Minibatch Loss= 637.1033, Training Accuracy= 0.780\n",
      "Step 96400, Minibatch Loss= 2370.8523, Training Accuracy= 0.730\n",
      "Step 96500, Minibatch Loss= 3150.6130, Training Accuracy= 0.780\n",
      "Step 96600, Minibatch Loss= 2689.2937, Training Accuracy= 0.620\n",
      "Step 96700, Minibatch Loss= 2411.0120, Training Accuracy= 0.730\n",
      "Step 96800, Minibatch Loss= 692.2870, Training Accuracy= 0.780\n",
      "Step 96900, Minibatch Loss= 2474.7871, Training Accuracy= 0.650\n",
      "Step 97000, Minibatch Loss= 785.0089, Training Accuracy= 0.830\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(X_train/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = random_batch(np.concatenate([X_train, y_train], axis=1),\n",
    "                                              batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print \"Accuracy:\", accuracy.eval({x: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
