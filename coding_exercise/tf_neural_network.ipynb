{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Native and Third Party Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/Desktop/Projects/tf/venv/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original data frame: (1000, 21)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/abhishek/Desktop/Projects/tf/yet_another_ML_tutorial/coding_exercise/')\n",
    "raw_data = pd.read_csv(\"./CreditDataset.csv\", header=None)\n",
    "print \"Shape of original data frame:\", raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     object\n",
      "1      int64\n",
      "2     object\n",
      "3     object\n",
      "4      int64\n",
      "5     object\n",
      "6     object\n",
      "7      int64\n",
      "8     object\n",
      "9     object\n",
      "10     int64\n",
      "11    object\n",
      "12     int64\n",
      "13    object\n",
      "14    object\n",
      "15     int64\n",
      "16    object\n",
      "17     int64\n",
      "18    object\n",
      "19    object\n",
      "20     int64\n",
      "dtype: object\n",
      "Shape of object data frame: (1000, 13)\n",
      "Shape of int64 data frame: (1000, 8)\n",
      "Type of int data frame: <class 'pandas.core.frame.DataFrame'>\n",
      "Empty DataFrame\n",
      "Columns: [0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Get data types\n",
    "print raw_data.dtypes\n",
    "obj_df = raw_data.select_dtypes(include=['object']).copy()\n",
    "print \"Shape of object data frame:\", obj_df.shape\n",
    "int_df = raw_data.select_dtypes(include=['int64']).copy()\n",
    "print \"Shape of int64 data frame:\", int_df.shape\n",
    "print \"Type of int data frame:\", type(int_df)\n",
    "\n",
    "# Check for null values in the columns containing categorical variables\n",
    "print obj_df[obj_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Categorical data has been converted into numerical data using `one-hot encoding` in `scikit-learn`. Output labels have been one-hot encoded using `numpy`. The resulting dataset has the shape `(1000,63)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 54)\n",
      "<type 'numpy.ndarray'>\n",
      "(1000, 8)\n",
      "(1000, 62)\n",
      "float64\n",
      "(1000, 63)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding of the columns containing categorical variables\n",
    "# Label encoder\n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = preprocessing.LabelEncoder()\n",
    "# FIT AND TRANSFORM. use df.apply() to apply le.fit_transform to all columns\n",
    "le_obj_df = obj_df.apply(le.fit_transform)\n",
    "# print raw_data.select_dtypes(include=['object']).head(5)\n",
    "# print le_obj_df.head()\n",
    "\n",
    "# One hot encoding of categorical variables\n",
    "# 1. INSTANTIATE\n",
    "encode_object = preprocessing.OneHotEncoder()\n",
    "# 2. FIT\n",
    "encode_object.fit(le_obj_df)\n",
    "# 3. Transform\n",
    "onehotlabels = encode_object.transform(le_obj_df).toarray()\n",
    "print onehotlabels.shape\n",
    "print type(onehotlabels)\n",
    "\n",
    "# Merge the int64 data frame with the one hot labels\n",
    "np_int_df = int_df.as_matrix()\n",
    "print np_int_df.shape\n",
    "processed_data = np.concatenate([onehotlabels, np_int_df], axis=1)\n",
    "print processed_data.shape\n",
    "\n",
    "# print processed_data[:,-1]\n",
    "print processed_data.dtype\n",
    "\n",
    "\n",
    "# Encode output for NN\n",
    "# encode_output = preprocessing.OneHotEncoder()\n",
    "# encode_output.fit(processed_data[:,-1])\n",
    "# output_onehotlabels = encode_output.transform(processed_data[:,-1])\n",
    "# print \"Shape of encoded one hot labels:\", output_onehotlabels.shape\n",
    "#\n",
    "\n",
    "raw_labels = np.array(processed_data[:,-1]).astype(int)\n",
    "encoded_labels = np.zeros((processed_data[:,-1].shape[0], 2))\n",
    "encoded_labels[np.arange(processed_data[:,-1].shape[0]), raw_labels-1] = 1\n",
    "\n",
    "\n",
    "processed_data = processed_data[:,0:61]\n",
    "processed_data = np.concatenate([processed_data, encoded_labels], axis=1)\n",
    "print processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "30% of the actual data has been kept as test data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data[:, 0:61],\n",
    "                                                    processed_data[:, 61:63],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 61) (300, 61)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2) (300, 2)\n"
     ]
    }
   ],
   "source": [
    "print y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Creation\n",
    "At each iteration of training, a mini-batch of the data shall be fed to the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(dataset, batch_size):\n",
    "    sample = dataset[np.random.choice(dataset.shape[0], batch_size, replace=False),:]\n",
    "    last_col_index = dataset.shape[1]-2\n",
    "    x = sample[:,0:last_col_index]\n",
    "    y = sample[:,last_col_index:last_col_index+2]\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "Two hidden layer each with 256 neurons. Network was trained with `Adam Optimizer`. Network parameters are mentioned in the snippet below:\n",
    "\n",
    "```python\n",
    "learning_rate = 0.001\n",
    "num_steps = 50000\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input: 61\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 50000\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "weighted_cost = True # Apply weight of 5 and 1 for FPs and TNs respectively\n",
    "false_neg_cost = 5.0\n",
    "false_pos_cost = 1.0\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = X_train.shape[1] \n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "print \"Number of input:\", num_input\n",
    "print \"Number of classes:\", num_classes\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "if weighted_cost:\n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(\n",
    "              targets=Y, logits=logits, pos_weight=false_neg_cost))\n",
    "else:\n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 635129.9375, Training Accuracy= 0.730\n",
      "Step 100, Minibatch Loss= 2885.2468, Training Accuracy= 0.560\n",
      "Step 200, Minibatch Loss= 14991.1396, Training Accuracy= 0.660\n",
      "Step 300, Minibatch Loss= 33021.5586, Training Accuracy= 0.320\n",
      "Step 400, Minibatch Loss= 18281.2617, Training Accuracy= 0.680\n",
      "Step 500, Minibatch Loss= 10451.6797, Training Accuracy= 0.530\n",
      "Step 600, Minibatch Loss= 2014.0500, Training Accuracy= 0.710\n",
      "Step 700, Minibatch Loss= 8452.2109, Training Accuracy= 0.750\n",
      "Step 800, Minibatch Loss= 17707.2500, Training Accuracy= 0.740\n",
      "Step 900, Minibatch Loss= 8238.7061, Training Accuracy= 0.540\n",
      "Step 1000, Minibatch Loss= 19186.8008, Training Accuracy= 0.650\n",
      "Step 1100, Minibatch Loss= 32687.4941, Training Accuracy= 0.240\n",
      "Step 1200, Minibatch Loss= 7185.9683, Training Accuracy= 0.550\n",
      "Step 1300, Minibatch Loss= 6489.5181, Training Accuracy= 0.680\n",
      "Step 1400, Minibatch Loss= 4641.2939, Training Accuracy= 0.620\n",
      "Step 1500, Minibatch Loss= 6604.1514, Training Accuracy= 0.620\n",
      "Step 1600, Minibatch Loss= 4584.7817, Training Accuracy= 0.560\n",
      "Step 1700, Minibatch Loss= 9149.9121, Training Accuracy= 0.570\n",
      "Step 1800, Minibatch Loss= 7503.7300, Training Accuracy= 0.700\n",
      "Step 1900, Minibatch Loss= 22363.0996, Training Accuracy= 0.780\n",
      "Step 2000, Minibatch Loss= 14741.0752, Training Accuracy= 0.770\n",
      "Step 2100, Minibatch Loss= 10098.0615, Training Accuracy= 0.760\n",
      "Step 2200, Minibatch Loss= 3545.8179, Training Accuracy= 0.590\n",
      "Step 2300, Minibatch Loss= 1672.8882, Training Accuracy= 0.710\n",
      "Step 2400, Minibatch Loss= 4434.7114, Training Accuracy= 0.730\n",
      "Step 2500, Minibatch Loss= 6161.6289, Training Accuracy= 0.730\n",
      "Step 2600, Minibatch Loss= 5551.7090, Training Accuracy= 0.630\n",
      "Step 2700, Minibatch Loss= 14357.9834, Training Accuracy= 0.650\n",
      "Step 2800, Minibatch Loss= 1861.5344, Training Accuracy= 0.710\n",
      "Step 2900, Minibatch Loss= 10951.7773, Training Accuracy= 0.520\n",
      "Step 3000, Minibatch Loss= 10327.2852, Training Accuracy= 0.720\n",
      "Step 3100, Minibatch Loss= 16294.2695, Training Accuracy= 0.690\n",
      "Step 3200, Minibatch Loss= 19171.3203, Training Accuracy= 0.450\n",
      "Step 3300, Minibatch Loss= 9048.1875, Training Accuracy= 0.810\n",
      "Step 3400, Minibatch Loss= 14289.0303, Training Accuracy= 0.500\n",
      "Step 3500, Minibatch Loss= 2597.4941, Training Accuracy= 0.760\n",
      "Step 3600, Minibatch Loss= 16429.3594, Training Accuracy= 0.680\n",
      "Step 3700, Minibatch Loss= 2523.3801, Training Accuracy= 0.680\n",
      "Step 3800, Minibatch Loss= 10360.1377, Training Accuracy= 0.710\n",
      "Step 3900, Minibatch Loss= 6675.1226, Training Accuracy= 0.780\n",
      "Step 4000, Minibatch Loss= 14697.4404, Training Accuracy= 0.700\n",
      "Step 4100, Minibatch Loss= 4611.8677, Training Accuracy= 0.710\n",
      "Step 4200, Minibatch Loss= 2093.0176, Training Accuracy= 0.690\n",
      "Step 4300, Minibatch Loss= 5968.8975, Training Accuracy= 0.760\n",
      "Step 4400, Minibatch Loss= 7235.1191, Training Accuracy= 0.680\n",
      "Step 4500, Minibatch Loss= 7766.9551, Training Accuracy= 0.670\n",
      "Step 4600, Minibatch Loss= 19622.8105, Training Accuracy= 0.660\n",
      "Step 4700, Minibatch Loss= 3002.6252, Training Accuracy= 0.780\n",
      "Step 4800, Minibatch Loss= 7513.6255, Training Accuracy= 0.760\n",
      "Step 4900, Minibatch Loss= 6469.8794, Training Accuracy= 0.570\n",
      "Step 5000, Minibatch Loss= 19353.7910, Training Accuracy= 0.520\n",
      "Step 5100, Minibatch Loss= 10223.9834, Training Accuracy= 0.730\n",
      "Step 5200, Minibatch Loss= 3049.5056, Training Accuracy= 0.720\n",
      "Step 5300, Minibatch Loss= 8750.6641, Training Accuracy= 0.760\n",
      "Step 5400, Minibatch Loss= 12508.0225, Training Accuracy= 0.780\n",
      "Step 5500, Minibatch Loss= 10790.2939, Training Accuracy= 0.430\n",
      "Step 5600, Minibatch Loss= 9257.0791, Training Accuracy= 0.700\n",
      "Step 5700, Minibatch Loss= 8032.2998, Training Accuracy= 0.660\n",
      "Step 5800, Minibatch Loss= 2200.0112, Training Accuracy= 0.740\n",
      "Step 5900, Minibatch Loss= 3682.9551, Training Accuracy= 0.710\n",
      "Step 6000, Minibatch Loss= 13157.5352, Training Accuracy= 0.710\n",
      "Step 6100, Minibatch Loss= 7152.8096, Training Accuracy= 0.650\n",
      "Step 6200, Minibatch Loss= 35068.2500, Training Accuracy= 0.670\n",
      "Step 6300, Minibatch Loss= 9778.5312, Training Accuracy= 0.720\n",
      "Step 6400, Minibatch Loss= 3541.9143, Training Accuracy= 0.800\n",
      "Step 6500, Minibatch Loss= 10303.6865, Training Accuracy= 0.510\n",
      "Step 6600, Minibatch Loss= 18644.0820, Training Accuracy= 0.720\n",
      "Step 6700, Minibatch Loss= 8238.9092, Training Accuracy= 0.710\n",
      "Step 6800, Minibatch Loss= 9348.1787, Training Accuracy= 0.590\n",
      "Step 6900, Minibatch Loss= 4590.9531, Training Accuracy= 0.650\n",
      "Step 7000, Minibatch Loss= 2905.8096, Training Accuracy= 0.770\n",
      "Step 7100, Minibatch Loss= 2652.3047, Training Accuracy= 0.790\n",
      "Step 7200, Minibatch Loss= 3037.6138, Training Accuracy= 0.690\n",
      "Step 7300, Minibatch Loss= 14776.7949, Training Accuracy= 0.660\n",
      "Step 7400, Minibatch Loss= 7456.2471, Training Accuracy= 0.630\n",
      "Step 7500, Minibatch Loss= 4866.7280, Training Accuracy= 0.770\n",
      "Step 7600, Minibatch Loss= 9777.5859, Training Accuracy= 0.660\n",
      "Step 7700, Minibatch Loss= 7403.6826, Training Accuracy= 0.750\n",
      "Step 7800, Minibatch Loss= 10921.6162, Training Accuracy= 0.770\n",
      "Step 7900, Minibatch Loss= 11378.8535, Training Accuracy= 0.730\n",
      "Step 8000, Minibatch Loss= 14967.2500, Training Accuracy= 0.400\n",
      "Step 8100, Minibatch Loss= 9807.1836, Training Accuracy= 0.730\n",
      "Step 8200, Minibatch Loss= 8551.7588, Training Accuracy= 0.780\n",
      "Step 8300, Minibatch Loss= 8949.7412, Training Accuracy= 0.710\n",
      "Step 8400, Minibatch Loss= 8199.6934, Training Accuracy= 0.700\n",
      "Step 8500, Minibatch Loss= 4611.8320, Training Accuracy= 0.740\n",
      "Step 8600, Minibatch Loss= 5555.7988, Training Accuracy= 0.770\n",
      "Step 8700, Minibatch Loss= 10669.9854, Training Accuracy= 0.700\n",
      "Step 8800, Minibatch Loss= 2656.4673, Training Accuracy= 0.850\n",
      "Step 8900, Minibatch Loss= 3461.4888, Training Accuracy= 0.800\n",
      "Step 9000, Minibatch Loss= 15110.8574, Training Accuracy= 0.480\n",
      "Step 9100, Minibatch Loss= 6724.8564, Training Accuracy= 0.680\n",
      "Step 9200, Minibatch Loss= 5706.1318, Training Accuracy= 0.750\n",
      "Step 9300, Minibatch Loss= 8270.1387, Training Accuracy= 0.750\n",
      "Step 9400, Minibatch Loss= 6959.8276, Training Accuracy= 0.740\n",
      "Step 9500, Minibatch Loss= 4097.4702, Training Accuracy= 0.770\n",
      "Step 9600, Minibatch Loss= 3179.7295, Training Accuracy= 0.800\n",
      "Step 9700, Minibatch Loss= 8384.4092, Training Accuracy= 0.750\n",
      "Step 9800, Minibatch Loss= 6520.8262, Training Accuracy= 0.800\n",
      "Step 9900, Minibatch Loss= 13021.4053, Training Accuracy= 0.770\n",
      "Step 10000, Minibatch Loss= 7666.6489, Training Accuracy= 0.580\n",
      "Step 10100, Minibatch Loss= 16484.6230, Training Accuracy= 0.540\n",
      "Step 10200, Minibatch Loss= 25491.4824, Training Accuracy= 0.700\n",
      "Step 10300, Minibatch Loss= 9928.6523, Training Accuracy= 0.680\n",
      "Step 10400, Minibatch Loss= 3704.3650, Training Accuracy= 0.720\n",
      "Step 10500, Minibatch Loss= 5354.0605, Training Accuracy= 0.720\n",
      "Step 10600, Minibatch Loss= 19055.3691, Training Accuracy= 0.750\n",
      "Step 10700, Minibatch Loss= 17497.4727, Training Accuracy= 0.720\n",
      "Step 10800, Minibatch Loss= 8142.7832, Training Accuracy= 0.720\n",
      "Step 10900, Minibatch Loss= 21468.4805, Training Accuracy= 0.350\n",
      "Step 11000, Minibatch Loss= 1905.5557, Training Accuracy= 0.750\n",
      "Step 11100, Minibatch Loss= 1824.7506, Training Accuracy= 0.720\n",
      "Step 11200, Minibatch Loss= 9403.0752, Training Accuracy= 0.760\n",
      "Step 11300, Minibatch Loss= 12302.0625, Training Accuracy= 0.640\n",
      "Step 11400, Minibatch Loss= 7297.8086, Training Accuracy= 0.750\n",
      "Step 11500, Minibatch Loss= 2930.6611, Training Accuracy= 0.750\n",
      "Step 11600, Minibatch Loss= 5069.7217, Training Accuracy= 0.670\n",
      "Step 11700, Minibatch Loss= 7474.2476, Training Accuracy= 0.660\n",
      "Step 11800, Minibatch Loss= 4999.7505, Training Accuracy= 0.770\n",
      "Step 11900, Minibatch Loss= 14548.9629, Training Accuracy= 0.700\n",
      "Step 12000, Minibatch Loss= 7834.6030, Training Accuracy= 0.740\n",
      "Step 12100, Minibatch Loss= 13992.2773, Training Accuracy= 0.620\n",
      "Step 12200, Minibatch Loss= 13616.8896, Training Accuracy= 0.780\n",
      "Step 12300, Minibatch Loss= 2494.6218, Training Accuracy= 0.790\n",
      "Step 12400, Minibatch Loss= 7444.5811, Training Accuracy= 0.550\n",
      "Step 12500, Minibatch Loss= 12203.5361, Training Accuracy= 0.750\n",
      "Step 12600, Minibatch Loss= 5609.4692, Training Accuracy= 0.730\n",
      "Step 12700, Minibatch Loss= 18450.3633, Training Accuracy= 0.770\n",
      "Step 12800, Minibatch Loss= 5857.4458, Training Accuracy= 0.780\n",
      "Step 12900, Minibatch Loss= 12841.6221, Training Accuracy= 0.790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13000, Minibatch Loss= 15688.1777, Training Accuracy= 0.480\n",
      "Step 13100, Minibatch Loss= 8460.1104, Training Accuracy= 0.710\n",
      "Step 13200, Minibatch Loss= 5064.1221, Training Accuracy= 0.720\n",
      "Step 13300, Minibatch Loss= 3016.5525, Training Accuracy= 0.760\n",
      "Step 13400, Minibatch Loss= 2787.6382, Training Accuracy= 0.730\n",
      "Step 13500, Minibatch Loss= 15361.3975, Training Accuracy= 0.460\n",
      "Step 13600, Minibatch Loss= 10142.9404, Training Accuracy= 0.590\n",
      "Step 13700, Minibatch Loss= 18238.1992, Training Accuracy= 0.650\n",
      "Step 13800, Minibatch Loss= 11876.3799, Training Accuracy= 0.690\n",
      "Step 13900, Minibatch Loss= 27740.5723, Training Accuracy= 0.420\n",
      "Step 14000, Minibatch Loss= 4211.9092, Training Accuracy= 0.750\n",
      "Step 14100, Minibatch Loss= 17109.5605, Training Accuracy= 0.480\n",
      "Step 14200, Minibatch Loss= 9249.3701, Training Accuracy= 0.700\n",
      "Step 14300, Minibatch Loss= 4118.9023, Training Accuracy= 0.760\n",
      "Step 14400, Minibatch Loss= 4394.8154, Training Accuracy= 0.760\n",
      "Step 14500, Minibatch Loss= 4466.7095, Training Accuracy= 0.610\n",
      "Step 14600, Minibatch Loss= 11226.0713, Training Accuracy= 0.760\n",
      "Step 14700, Minibatch Loss= 10259.8184, Training Accuracy= 0.800\n",
      "Step 14800, Minibatch Loss= 2937.1772, Training Accuracy= 0.800\n",
      "Step 14900, Minibatch Loss= 5873.9375, Training Accuracy= 0.700\n",
      "Step 15000, Minibatch Loss= 6026.5317, Training Accuracy= 0.770\n",
      "Step 15100, Minibatch Loss= 8761.8555, Training Accuracy= 0.710\n",
      "Step 15200, Minibatch Loss= 11409.2363, Training Accuracy= 0.690\n",
      "Step 15300, Minibatch Loss= 2117.4131, Training Accuracy= 0.730\n",
      "Step 15400, Minibatch Loss= 7530.7886, Training Accuracy= 0.740\n",
      "Step 15500, Minibatch Loss= 21192.1133, Training Accuracy= 0.770\n",
      "Step 15600, Minibatch Loss= 8232.9346, Training Accuracy= 0.730\n",
      "Step 15700, Minibatch Loss= 5633.3989, Training Accuracy= 0.790\n",
      "Step 15800, Minibatch Loss= 4515.0513, Training Accuracy= 0.780\n",
      "Step 15900, Minibatch Loss= 10593.5977, Training Accuracy= 0.660\n",
      "Step 16000, Minibatch Loss= 1137.0629, Training Accuracy= 0.870\n",
      "Step 16100, Minibatch Loss= 5050.1802, Training Accuracy= 0.750\n",
      "Step 16200, Minibatch Loss= 12231.6875, Training Accuracy= 0.750\n",
      "Step 16300, Minibatch Loss= 2591.4316, Training Accuracy= 0.720\n",
      "Step 16400, Minibatch Loss= 5487.9692, Training Accuracy= 0.790\n",
      "Step 16500, Minibatch Loss= 5151.2217, Training Accuracy= 0.620\n",
      "Step 16600, Minibatch Loss= 11487.0088, Training Accuracy= 0.730\n",
      "Step 16700, Minibatch Loss= 2498.2568, Training Accuracy= 0.730\n",
      "Step 16800, Minibatch Loss= 2694.8303, Training Accuracy= 0.740\n",
      "Step 16900, Minibatch Loss= 2453.6887, Training Accuracy= 0.790\n",
      "Step 17000, Minibatch Loss= 7584.4912, Training Accuracy= 0.770\n",
      "Step 17100, Minibatch Loss= 3811.5479, Training Accuracy= 0.700\n",
      "Step 17200, Minibatch Loss= 15058.0029, Training Accuracy= 0.710\n",
      "Step 17300, Minibatch Loss= 4046.4238, Training Accuracy= 0.790\n",
      "Step 17400, Minibatch Loss= 5166.7290, Training Accuracy= 0.660\n",
      "Step 17500, Minibatch Loss= 4149.3501, Training Accuracy= 0.830\n",
      "Step 17600, Minibatch Loss= 2365.5750, Training Accuracy= 0.810\n",
      "Step 17700, Minibatch Loss= 15913.6475, Training Accuracy= 0.480\n",
      "Step 17800, Minibatch Loss= 5213.0898, Training Accuracy= 0.810\n",
      "Step 17900, Minibatch Loss= 2688.6877, Training Accuracy= 0.730\n",
      "Step 18000, Minibatch Loss= 6110.1274, Training Accuracy= 0.740\n",
      "Step 18100, Minibatch Loss= 8212.9443, Training Accuracy= 0.730\n",
      "Step 18200, Minibatch Loss= 9636.1055, Training Accuracy= 0.760\n",
      "Step 18300, Minibatch Loss= 7204.2974, Training Accuracy= 0.790\n",
      "Step 18400, Minibatch Loss= 7209.3750, Training Accuracy= 0.670\n",
      "Step 18500, Minibatch Loss= 2681.1343, Training Accuracy= 0.740\n",
      "Step 18600, Minibatch Loss= 26378.0352, Training Accuracy= 0.730\n",
      "Step 18700, Minibatch Loss= 13963.2109, Training Accuracy= 0.800\n",
      "Step 18800, Minibatch Loss= 8848.1338, Training Accuracy= 0.740\n",
      "Step 18900, Minibatch Loss= 3153.6082, Training Accuracy= 0.750\n",
      "Step 19000, Minibatch Loss= 7670.4404, Training Accuracy= 0.770\n",
      "Step 19100, Minibatch Loss= 12021.2129, Training Accuracy= 0.490\n",
      "Step 19200, Minibatch Loss= 11609.3027, Training Accuracy= 0.710\n",
      "Step 19300, Minibatch Loss= 13064.4062, Training Accuracy= 0.520\n",
      "Step 19400, Minibatch Loss= 5041.0630, Training Accuracy= 0.610\n",
      "Step 19500, Minibatch Loss= 27100.8691, Training Accuracy= 0.490\n",
      "Step 19600, Minibatch Loss= 11737.9541, Training Accuracy= 0.630\n",
      "Step 19700, Minibatch Loss= 10323.5742, Training Accuracy= 0.740\n",
      "Step 19800, Minibatch Loss= 2962.9543, Training Accuracy= 0.750\n",
      "Step 19900, Minibatch Loss= 1943.3484, Training Accuracy= 0.730\n",
      "Step 20000, Minibatch Loss= 4606.2485, Training Accuracy= 0.750\n",
      "Step 20100, Minibatch Loss= 3274.5437, Training Accuracy= 0.830\n",
      "Step 20200, Minibatch Loss= 8083.1558, Training Accuracy= 0.730\n",
      "Step 20300, Minibatch Loss= 3172.1863, Training Accuracy= 0.720\n",
      "Step 20400, Minibatch Loss= 3042.7656, Training Accuracy= 0.750\n",
      "Step 20500, Minibatch Loss= 10607.9775, Training Accuracy= 0.790\n",
      "Step 20600, Minibatch Loss= 5372.0957, Training Accuracy= 0.550\n",
      "Step 20700, Minibatch Loss= 12378.7646, Training Accuracy= 0.400\n",
      "Step 20800, Minibatch Loss= 6078.7471, Training Accuracy= 0.740\n",
      "Step 20900, Minibatch Loss= 3836.0549, Training Accuracy= 0.820\n",
      "Step 21000, Minibatch Loss= 10141.2197, Training Accuracy= 0.490\n",
      "Step 21100, Minibatch Loss= 4161.1230, Training Accuracy= 0.730\n",
      "Step 21200, Minibatch Loss= 3723.8608, Training Accuracy= 0.800\n",
      "Step 21300, Minibatch Loss= 6049.9277, Training Accuracy= 0.610\n",
      "Step 21400, Minibatch Loss= 1662.9600, Training Accuracy= 0.790\n",
      "Step 21500, Minibatch Loss= 9419.1289, Training Accuracy= 0.810\n",
      "Step 21600, Minibatch Loss= 13072.2646, Training Accuracy= 0.580\n",
      "Step 21700, Minibatch Loss= 3992.7607, Training Accuracy= 0.770\n",
      "Step 21800, Minibatch Loss= 7896.4360, Training Accuracy= 0.610\n",
      "Step 21900, Minibatch Loss= 13088.1641, Training Accuracy= 0.430\n",
      "Step 22000, Minibatch Loss= 17114.8457, Training Accuracy= 0.740\n",
      "Step 22100, Minibatch Loss= 7448.4399, Training Accuracy= 0.680\n",
      "Step 22200, Minibatch Loss= 12279.4551, Training Accuracy= 0.720\n",
      "Step 22300, Minibatch Loss= 5105.1274, Training Accuracy= 0.730\n",
      "Step 22400, Minibatch Loss= 7168.3901, Training Accuracy= 0.630\n",
      "Step 22500, Minibatch Loss= 3466.5986, Training Accuracy= 0.750\n",
      "Step 22600, Minibatch Loss= 2569.3770, Training Accuracy= 0.740\n",
      "Step 22700, Minibatch Loss= 16518.8379, Training Accuracy= 0.630\n",
      "Step 22800, Minibatch Loss= 14279.8271, Training Accuracy= 0.780\n",
      "Step 22900, Minibatch Loss= 2450.4487, Training Accuracy= 0.820\n",
      "Step 23000, Minibatch Loss= 5297.9985, Training Accuracy= 0.620\n",
      "Step 23100, Minibatch Loss= 4663.3853, Training Accuracy= 0.820\n",
      "Step 23200, Minibatch Loss= 22386.1445, Training Accuracy= 0.650\n",
      "Step 23300, Minibatch Loss= 3604.5237, Training Accuracy= 0.690\n",
      "Step 23400, Minibatch Loss= 6569.3735, Training Accuracy= 0.740\n",
      "Step 23500, Minibatch Loss= 11637.8320, Training Accuracy= 0.570\n",
      "Step 23600, Minibatch Loss= 7969.1064, Training Accuracy= 0.710\n",
      "Step 23700, Minibatch Loss= 10864.6299, Training Accuracy= 0.590\n",
      "Step 23800, Minibatch Loss= 10346.5146, Training Accuracy= 0.720\n",
      "Step 23900, Minibatch Loss= 2453.7241, Training Accuracy= 0.720\n",
      "Step 24000, Minibatch Loss= 3655.5200, Training Accuracy= 0.740\n",
      "Step 24100, Minibatch Loss= 7959.3262, Training Accuracy= 0.680\n",
      "Step 24200, Minibatch Loss= 3725.8574, Training Accuracy= 0.790\n",
      "Step 24300, Minibatch Loss= 2669.6716, Training Accuracy= 0.810\n",
      "Step 24400, Minibatch Loss= 5356.9004, Training Accuracy= 0.770\n",
      "Step 24500, Minibatch Loss= 6790.6924, Training Accuracy= 0.800\n",
      "Step 24600, Minibatch Loss= 1815.1193, Training Accuracy= 0.780\n",
      "Step 24700, Minibatch Loss= 10672.8760, Training Accuracy= 0.760\n",
      "Step 24800, Minibatch Loss= 2470.4363, Training Accuracy= 0.790\n",
      "Step 24900, Minibatch Loss= 1270.6079, Training Accuracy= 0.820\n",
      "Step 25000, Minibatch Loss= 2819.6106, Training Accuracy= 0.740\n",
      "Step 25100, Minibatch Loss= 4545.8833, Training Accuracy= 0.800\n",
      "Step 25200, Minibatch Loss= 3662.2800, Training Accuracy= 0.660\n",
      "Step 25300, Minibatch Loss= 17865.9766, Training Accuracy= 0.670\n",
      "Step 25400, Minibatch Loss= 11559.4814, Training Accuracy= 0.760\n",
      "Step 25500, Minibatch Loss= 13372.8203, Training Accuracy= 0.730\n",
      "Step 25600, Minibatch Loss= 3490.4175, Training Accuracy= 0.650\n",
      "Step 25700, Minibatch Loss= 12447.2109, Training Accuracy= 0.760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 25800, Minibatch Loss= 11104.0352, Training Accuracy= 0.680\n",
      "Step 25900, Minibatch Loss= 3177.7637, Training Accuracy= 0.810\n",
      "Step 26000, Minibatch Loss= 9249.8896, Training Accuracy= 0.730\n",
      "Step 26100, Minibatch Loss= 4270.5952, Training Accuracy= 0.720\n",
      "Step 26200, Minibatch Loss= 4268.8574, Training Accuracy= 0.630\n",
      "Step 26300, Minibatch Loss= 3556.6113, Training Accuracy= 0.770\n",
      "Step 26400, Minibatch Loss= 7686.4111, Training Accuracy= 0.720\n",
      "Step 26500, Minibatch Loss= 9107.5430, Training Accuracy= 0.440\n",
      "Step 26600, Minibatch Loss= 6094.8218, Training Accuracy= 0.580\n",
      "Step 26700, Minibatch Loss= 11458.1680, Training Accuracy= 0.810\n",
      "Step 26800, Minibatch Loss= 3160.6426, Training Accuracy= 0.740\n",
      "Step 26900, Minibatch Loss= 8776.0068, Training Accuracy= 0.800\n",
      "Step 27000, Minibatch Loss= 2687.4238, Training Accuracy= 0.810\n",
      "Step 27100, Minibatch Loss= 10534.6123, Training Accuracy= 0.750\n",
      "Step 27200, Minibatch Loss= 9860.5459, Training Accuracy= 0.720\n",
      "Step 27300, Minibatch Loss= 17147.6191, Training Accuracy= 0.760\n",
      "Step 27400, Minibatch Loss= 2906.8630, Training Accuracy= 0.720\n",
      "Step 27500, Minibatch Loss= 3862.7251, Training Accuracy= 0.680\n",
      "Step 27600, Minibatch Loss= 27412.0703, Training Accuracy= 0.630\n",
      "Step 27700, Minibatch Loss= 8318.9209, Training Accuracy= 0.750\n",
      "Step 27800, Minibatch Loss= 5717.6323, Training Accuracy= 0.750\n",
      "Step 27900, Minibatch Loss= 7847.7827, Training Accuracy= 0.680\n",
      "Step 28000, Minibatch Loss= 2467.7432, Training Accuracy= 0.720\n",
      "Step 28100, Minibatch Loss= 8124.9180, Training Accuracy= 0.600\n",
      "Step 28200, Minibatch Loss= 10255.8135, Training Accuracy= 0.760\n",
      "Step 28300, Minibatch Loss= 2471.3916, Training Accuracy= 0.770\n",
      "Step 28400, Minibatch Loss= 2819.9312, Training Accuracy= 0.790\n",
      "Step 28500, Minibatch Loss= 7902.9482, Training Accuracy= 0.550\n",
      "Step 28600, Minibatch Loss= 3866.9976, Training Accuracy= 0.740\n",
      "Step 28700, Minibatch Loss= 10803.9961, Training Accuracy= 0.690\n",
      "Step 28800, Minibatch Loss= 3664.7056, Training Accuracy= 0.720\n",
      "Step 28900, Minibatch Loss= 5208.7505, Training Accuracy= 0.800\n",
      "Step 29000, Minibatch Loss= 3184.2312, Training Accuracy= 0.720\n",
      "Step 29100, Minibatch Loss= 15494.3174, Training Accuracy= 0.730\n",
      "Step 29200, Minibatch Loss= 16199.1123, Training Accuracy= 0.690\n",
      "Step 29300, Minibatch Loss= 9430.3936, Training Accuracy= 0.590\n",
      "Step 29400, Minibatch Loss= 6476.2837, Training Accuracy= 0.740\n",
      "Step 29500, Minibatch Loss= 3158.2568, Training Accuracy= 0.810\n",
      "Step 29600, Minibatch Loss= 3509.2700, Training Accuracy= 0.710\n",
      "Step 29700, Minibatch Loss= 18089.9805, Training Accuracy= 0.720\n",
      "Step 29800, Minibatch Loss= 2963.9988, Training Accuracy= 0.750\n",
      "Step 29900, Minibatch Loss= 4352.6191, Training Accuracy= 0.770\n",
      "Step 30000, Minibatch Loss= 5121.1504, Training Accuracy= 0.780\n",
      "Step 30100, Minibatch Loss= 9844.6992, Training Accuracy= 0.740\n",
      "Step 30200, Minibatch Loss= 9924.7861, Training Accuracy= 0.700\n",
      "Step 30300, Minibatch Loss= 7205.9907, Training Accuracy= 0.760\n",
      "Step 30400, Minibatch Loss= 7519.0312, Training Accuracy= 0.670\n",
      "Step 30500, Minibatch Loss= 7295.3545, Training Accuracy= 0.740\n",
      "Step 30600, Minibatch Loss= 9289.5859, Training Accuracy= 0.710\n",
      "Step 30700, Minibatch Loss= 8456.2490, Training Accuracy= 0.810\n",
      "Step 30800, Minibatch Loss= 4982.7007, Training Accuracy= 0.770\n",
      "Step 30900, Minibatch Loss= 11591.0947, Training Accuracy= 0.720\n",
      "Step 31000, Minibatch Loss= 9993.9414, Training Accuracy= 0.730\n",
      "Step 31100, Minibatch Loss= 6192.1812, Training Accuracy= 0.790\n",
      "Step 31200, Minibatch Loss= 6085.9492, Training Accuracy= 0.700\n",
      "Step 31300, Minibatch Loss= 6811.2656, Training Accuracy= 0.730\n",
      "Step 31400, Minibatch Loss= 8182.8433, Training Accuracy= 0.590\n",
      "Step 31500, Minibatch Loss= 4562.8345, Training Accuracy= 0.750\n",
      "Step 31600, Minibatch Loss= 12220.5137, Training Accuracy= 0.690\n",
      "Step 31700, Minibatch Loss= 3704.1650, Training Accuracy= 0.720\n",
      "Step 31800, Minibatch Loss= 8900.2314, Training Accuracy= 0.720\n",
      "Step 31900, Minibatch Loss= 2837.7693, Training Accuracy= 0.770\n",
      "Step 32000, Minibatch Loss= 3695.0388, Training Accuracy= 0.770\n",
      "Step 32100, Minibatch Loss= 3414.3594, Training Accuracy= 0.740\n",
      "Step 32200, Minibatch Loss= 14471.7148, Training Accuracy= 0.700\n",
      "Step 32300, Minibatch Loss= 27236.4453, Training Accuracy= 0.430\n",
      "Step 32400, Minibatch Loss= 12261.2764, Training Accuracy= 0.600\n",
      "Step 32500, Minibatch Loss= 2608.7876, Training Accuracy= 0.770\n",
      "Step 32600, Minibatch Loss= 5112.1357, Training Accuracy= 0.800\n",
      "Step 32700, Minibatch Loss= 4051.5845, Training Accuracy= 0.660\n",
      "Step 32800, Minibatch Loss= 12832.4648, Training Accuracy= 0.620\n",
      "Step 32900, Minibatch Loss= 7639.7617, Training Accuracy= 0.720\n",
      "Step 33000, Minibatch Loss= 2345.4907, Training Accuracy= 0.800\n",
      "Step 33100, Minibatch Loss= 18960.2227, Training Accuracy= 0.550\n",
      "Step 33200, Minibatch Loss= 9108.5977, Training Accuracy= 0.600\n",
      "Step 33300, Minibatch Loss= 1666.5100, Training Accuracy= 0.820\n",
      "Step 33400, Minibatch Loss= 3423.6809, Training Accuracy= 0.770\n",
      "Step 33500, Minibatch Loss= 3215.7407, Training Accuracy= 0.770\n",
      "Step 33600, Minibatch Loss= 9078.9814, Training Accuracy= 0.490\n",
      "Step 33700, Minibatch Loss= 2929.8438, Training Accuracy= 0.780\n",
      "Step 33800, Minibatch Loss= 5653.1558, Training Accuracy= 0.760\n",
      "Step 33900, Minibatch Loss= 11497.9375, Training Accuracy= 0.700\n",
      "Step 34000, Minibatch Loss= 7269.8838, Training Accuracy= 0.590\n",
      "Step 34100, Minibatch Loss= 4362.6108, Training Accuracy= 0.780\n",
      "Step 34200, Minibatch Loss= 17132.3203, Training Accuracy= 0.370\n",
      "Step 34300, Minibatch Loss= 6960.7637, Training Accuracy= 0.720\n",
      "Step 34400, Minibatch Loss= 4793.9365, Training Accuracy= 0.790\n",
      "Step 34500, Minibatch Loss= 5100.4546, Training Accuracy= 0.730\n",
      "Step 34600, Minibatch Loss= 16515.0020, Training Accuracy= 0.540\n",
      "Step 34700, Minibatch Loss= 16942.1133, Training Accuracy= 0.680\n",
      "Step 34800, Minibatch Loss= 7441.8032, Training Accuracy= 0.710\n",
      "Step 34900, Minibatch Loss= 9144.4502, Training Accuracy= 0.550\n",
      "Step 35000, Minibatch Loss= 3183.0527, Training Accuracy= 0.770\n",
      "Step 35100, Minibatch Loss= 5071.3340, Training Accuracy= 0.790\n",
      "Step 35200, Minibatch Loss= 10238.4287, Training Accuracy= 0.750\n",
      "Step 35300, Minibatch Loss= 8946.9561, Training Accuracy= 0.650\n",
      "Step 35400, Minibatch Loss= 4518.2168, Training Accuracy= 0.780\n",
      "Step 35500, Minibatch Loss= 4388.1582, Training Accuracy= 0.770\n",
      "Step 35600, Minibatch Loss= 3086.2388, Training Accuracy= 0.820\n",
      "Step 35700, Minibatch Loss= 2615.3171, Training Accuracy= 0.720\n",
      "Step 35800, Minibatch Loss= 5618.0015, Training Accuracy= 0.720\n",
      "Step 35900, Minibatch Loss= 4412.7568, Training Accuracy= 0.850\n",
      "Step 36000, Minibatch Loss= 8570.5684, Training Accuracy= 0.750\n",
      "Step 36100, Minibatch Loss= 4011.6763, Training Accuracy= 0.720\n",
      "Step 36200, Minibatch Loss= 8369.1904, Training Accuracy= 0.830\n",
      "Step 36300, Minibatch Loss= 3418.6316, Training Accuracy= 0.770\n",
      "Step 36400, Minibatch Loss= 2535.1375, Training Accuracy= 0.720\n",
      "Step 36500, Minibatch Loss= 3138.3938, Training Accuracy= 0.770\n",
      "Step 36600, Minibatch Loss= 1748.3676, Training Accuracy= 0.770\n",
      "Step 36700, Minibatch Loss= 6574.2837, Training Accuracy= 0.720\n",
      "Step 36800, Minibatch Loss= 18758.4102, Training Accuracy= 0.650\n",
      "Step 36900, Minibatch Loss= 2753.7419, Training Accuracy= 0.780\n",
      "Step 37000, Minibatch Loss= 5113.4380, Training Accuracy= 0.790\n",
      "Step 37100, Minibatch Loss= 12792.1680, Training Accuracy= 0.650\n",
      "Step 37200, Minibatch Loss= 3175.9211, Training Accuracy= 0.780\n",
      "Step 37300, Minibatch Loss= 16424.3457, Training Accuracy= 0.730\n",
      "Step 37400, Minibatch Loss= 13087.9199, Training Accuracy= 0.720\n",
      "Step 37500, Minibatch Loss= 3934.0889, Training Accuracy= 0.810\n",
      "Step 37600, Minibatch Loss= 5235.3389, Training Accuracy= 0.810\n",
      "Step 37700, Minibatch Loss= 11259.5947, Training Accuracy= 0.760\n",
      "Step 37800, Minibatch Loss= 4594.7437, Training Accuracy= 0.640\n",
      "Step 37900, Minibatch Loss= 5448.1562, Training Accuracy= 0.720\n",
      "Step 38000, Minibatch Loss= 4330.8486, Training Accuracy= 0.760\n",
      "Step 38100, Minibatch Loss= 3906.0171, Training Accuracy= 0.680\n",
      "Step 38200, Minibatch Loss= 2681.4812, Training Accuracy= 0.650\n",
      "Step 38300, Minibatch Loss= 5481.3188, Training Accuracy= 0.760\n",
      "Step 38400, Minibatch Loss= 6545.2515, Training Accuracy= 0.760\n",
      "Step 38500, Minibatch Loss= 9051.4941, Training Accuracy= 0.630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 38600, Minibatch Loss= 8567.9873, Training Accuracy= 0.550\n",
      "Step 38700, Minibatch Loss= 4804.6401, Training Accuracy= 0.690\n",
      "Step 38800, Minibatch Loss= 11417.9824, Training Accuracy= 0.670\n",
      "Step 38900, Minibatch Loss= 7183.2954, Training Accuracy= 0.600\n",
      "Step 39000, Minibatch Loss= 4263.4678, Training Accuracy= 0.670\n",
      "Step 39100, Minibatch Loss= 5848.5151, Training Accuracy= 0.750\n",
      "Step 39200, Minibatch Loss= 10621.1084, Training Accuracy= 0.620\n",
      "Step 39300, Minibatch Loss= 9774.4189, Training Accuracy= 0.630\n",
      "Step 39400, Minibatch Loss= 7093.9849, Training Accuracy= 0.810\n",
      "Step 39500, Minibatch Loss= 3826.5947, Training Accuracy= 0.720\n",
      "Step 39600, Minibatch Loss= 9021.4863, Training Accuracy= 0.620\n",
      "Step 39700, Minibatch Loss= 3686.5637, Training Accuracy= 0.650\n",
      "Step 39800, Minibatch Loss= 2672.4575, Training Accuracy= 0.750\n",
      "Step 39900, Minibatch Loss= 3135.4463, Training Accuracy= 0.780\n",
      "Step 40000, Minibatch Loss= 13193.3115, Training Accuracy= 0.680\n",
      "Step 40100, Minibatch Loss= 23555.6797, Training Accuracy= 0.510\n",
      "Step 40200, Minibatch Loss= 4686.8252, Training Accuracy= 0.670\n",
      "Step 40300, Minibatch Loss= 2115.6670, Training Accuracy= 0.820\n",
      "Step 40400, Minibatch Loss= 12379.7148, Training Accuracy= 0.500\n",
      "Step 40500, Minibatch Loss= 5096.7769, Training Accuracy= 0.710\n",
      "Step 40600, Minibatch Loss= 10577.9854, Training Accuracy= 0.660\n",
      "Step 40700, Minibatch Loss= 3758.1252, Training Accuracy= 0.780\n",
      "Step 40800, Minibatch Loss= 20509.2402, Training Accuracy= 0.420\n",
      "Step 40900, Minibatch Loss= 5386.6577, Training Accuracy= 0.690\n",
      "Step 41000, Minibatch Loss= 2278.6108, Training Accuracy= 0.770\n",
      "Step 41100, Minibatch Loss= 14116.6338, Training Accuracy= 0.750\n",
      "Step 41200, Minibatch Loss= 5840.9927, Training Accuracy= 0.720\n",
      "Step 41300, Minibatch Loss= 2972.6494, Training Accuracy= 0.740\n",
      "Step 41400, Minibatch Loss= 11089.8740, Training Accuracy= 0.610\n",
      "Step 41500, Minibatch Loss= 6012.8184, Training Accuracy= 0.750\n",
      "Step 41600, Minibatch Loss= 4386.7026, Training Accuracy= 0.750\n",
      "Step 41700, Minibatch Loss= 3997.3423, Training Accuracy= 0.730\n",
      "Step 41800, Minibatch Loss= 14568.6641, Training Accuracy= 0.710\n",
      "Step 41900, Minibatch Loss= 9699.2334, Training Accuracy= 0.600\n",
      "Step 42000, Minibatch Loss= 9355.1025, Training Accuracy= 0.700\n",
      "Step 42100, Minibatch Loss= 2206.1287, Training Accuracy= 0.760\n",
      "Step 42200, Minibatch Loss= 1831.1589, Training Accuracy= 0.790\n",
      "Step 42300, Minibatch Loss= 4082.8970, Training Accuracy= 0.660\n",
      "Step 42400, Minibatch Loss= 5846.6719, Training Accuracy= 0.780\n",
      "Step 42500, Minibatch Loss= 2053.0002, Training Accuracy= 0.820\n",
      "Step 42600, Minibatch Loss= 8458.6748, Training Accuracy= 0.470\n",
      "Step 42700, Minibatch Loss= 10734.6426, Training Accuracy= 0.650\n",
      "Step 42800, Minibatch Loss= 5863.9995, Training Accuracy= 0.660\n",
      "Step 42900, Minibatch Loss= 9227.4434, Training Accuracy= 0.700\n",
      "Step 43000, Minibatch Loss= 5119.2979, Training Accuracy= 0.680\n",
      "Step 43100, Minibatch Loss= 9681.6484, Training Accuracy= 0.610\n",
      "Step 43200, Minibatch Loss= 5696.4531, Training Accuracy= 0.740\n",
      "Step 43300, Minibatch Loss= 3473.4082, Training Accuracy= 0.810\n",
      "Step 43400, Minibatch Loss= 6016.2090, Training Accuracy= 0.750\n",
      "Step 43500, Minibatch Loss= 7502.4912, Training Accuracy= 0.710\n",
      "Step 43600, Minibatch Loss= 3555.2378, Training Accuracy= 0.660\n",
      "Step 43700, Minibatch Loss= 22273.5547, Training Accuracy= 0.480\n",
      "Step 43800, Minibatch Loss= 8257.5332, Training Accuracy= 0.500\n",
      "Step 43900, Minibatch Loss= 7847.9795, Training Accuracy= 0.740\n",
      "Step 44000, Minibatch Loss= 14140.1016, Training Accuracy= 0.640\n",
      "Step 44100, Minibatch Loss= 4325.5356, Training Accuracy= 0.660\n",
      "Step 44200, Minibatch Loss= 2106.6973, Training Accuracy= 0.810\n",
      "Step 44300, Minibatch Loss= 12574.1865, Training Accuracy= 0.490\n",
      "Step 44400, Minibatch Loss= 5094.7246, Training Accuracy= 0.670\n",
      "Step 44500, Minibatch Loss= 2754.4963, Training Accuracy= 0.830\n",
      "Step 44600, Minibatch Loss= 2028.1234, Training Accuracy= 0.760\n",
      "Step 44700, Minibatch Loss= 7583.3213, Training Accuracy= 0.740\n",
      "Step 44800, Minibatch Loss= 8034.6387, Training Accuracy= 0.670\n",
      "Step 44900, Minibatch Loss= 5880.2661, Training Accuracy= 0.670\n",
      "Step 45000, Minibatch Loss= 3438.5068, Training Accuracy= 0.680\n",
      "Step 45100, Minibatch Loss= 4237.1631, Training Accuracy= 0.740\n",
      "Step 45200, Minibatch Loss= 4888.4438, Training Accuracy= 0.600\n",
      "Step 45300, Minibatch Loss= 10435.6621, Training Accuracy= 0.750\n",
      "Step 45400, Minibatch Loss= 4860.4253, Training Accuracy= 0.620\n",
      "Step 45500, Minibatch Loss= 1579.6240, Training Accuracy= 0.810\n",
      "Step 45600, Minibatch Loss= 10970.3496, Training Accuracy= 0.650\n",
      "Step 45700, Minibatch Loss= 5896.1958, Training Accuracy= 0.720\n",
      "Step 45800, Minibatch Loss= 7633.2773, Training Accuracy= 0.600\n",
      "Step 45900, Minibatch Loss= 2286.8914, Training Accuracy= 0.710\n",
      "Step 46000, Minibatch Loss= 9270.1787, Training Accuracy= 0.800\n",
      "Step 46100, Minibatch Loss= 2927.5347, Training Accuracy= 0.730\n",
      "Step 46200, Minibatch Loss= 4167.5186, Training Accuracy= 0.760\n",
      "Step 46300, Minibatch Loss= 5091.1602, Training Accuracy= 0.610\n",
      "Step 46400, Minibatch Loss= 6572.1274, Training Accuracy= 0.580\n",
      "Step 46500, Minibatch Loss= 13163.7900, Training Accuracy= 0.640\n",
      "Step 46600, Minibatch Loss= 2079.1733, Training Accuracy= 0.750\n",
      "Step 46700, Minibatch Loss= 3175.5007, Training Accuracy= 0.700\n",
      "Step 46800, Minibatch Loss= 2044.4639, Training Accuracy= 0.740\n",
      "Step 46900, Minibatch Loss= 1093.8213, Training Accuracy= 0.780\n",
      "Step 47000, Minibatch Loss= 5151.4214, Training Accuracy= 0.750\n",
      "Step 47100, Minibatch Loss= 2472.6743, Training Accuracy= 0.830\n",
      "Step 47200, Minibatch Loss= 2530.0054, Training Accuracy= 0.730\n",
      "Step 47300, Minibatch Loss= 24145.5625, Training Accuracy= 0.380\n",
      "Step 47400, Minibatch Loss= 12248.9414, Training Accuracy= 0.630\n",
      "Step 47500, Minibatch Loss= 6397.5112, Training Accuracy= 0.670\n",
      "Step 47600, Minibatch Loss= 4773.7036, Training Accuracy= 0.810\n",
      "Step 47700, Minibatch Loss= 1888.2953, Training Accuracy= 0.760\n",
      "Step 47800, Minibatch Loss= 8363.4600, Training Accuracy= 0.570\n",
      "Step 47900, Minibatch Loss= 3772.2568, Training Accuracy= 0.810\n",
      "Step 48000, Minibatch Loss= 4686.7236, Training Accuracy= 0.710\n",
      "Step 48100, Minibatch Loss= 3179.8931, Training Accuracy= 0.750\n",
      "Step 48200, Minibatch Loss= 8371.1309, Training Accuracy= 0.770\n",
      "Step 48300, Minibatch Loss= 10528.6953, Training Accuracy= 0.550\n",
      "Step 48400, Minibatch Loss= 6648.8809, Training Accuracy= 0.780\n",
      "Step 48500, Minibatch Loss= 4976.7002, Training Accuracy= 0.610\n",
      "Step 48600, Minibatch Loss= 12607.7314, Training Accuracy= 0.750\n",
      "Step 48700, Minibatch Loss= 2429.4463, Training Accuracy= 0.780\n",
      "Step 48800, Minibatch Loss= 5899.2124, Training Accuracy= 0.780\n",
      "Step 48900, Minibatch Loss= 1893.5132, Training Accuracy= 0.790\n",
      "Step 49000, Minibatch Loss= 7274.5220, Training Accuracy= 0.720\n",
      "Step 49100, Minibatch Loss= 4099.1167, Training Accuracy= 0.700\n",
      "Step 49200, Minibatch Loss= 10411.9160, Training Accuracy= 0.590\n",
      "Step 49300, Minibatch Loss= 2622.5024, Training Accuracy= 0.750\n",
      "Step 49400, Minibatch Loss= 7751.2798, Training Accuracy= 0.520\n",
      "Step 49500, Minibatch Loss= 9840.6426, Training Accuracy= 0.680\n",
      "Step 49600, Minibatch Loss= 11189.3525, Training Accuracy= 0.480\n",
      "Step 49700, Minibatch Loss= 4827.6450, Training Accuracy= 0.680\n",
      "Step 49800, Minibatch Loss= 3402.3037, Training Accuracy= 0.790\n",
      "Step 49900, Minibatch Loss= 8998.2959, Training Accuracy= 0.690\n",
      "Step 50000, Minibatch Loss= 4776.7251, Training Accuracy= 0.740\n",
      "Optimization Finished!\n",
      "('Testing Accuracy:', 0.74333334)\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = random_batch(np.concatenate([X_train, y_train], axis=1), \n",
    "                                        batch_size) \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: X_test,\n",
    "                                      Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "Accuracy on the test set after about `50000` iterations was approx. `74%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
